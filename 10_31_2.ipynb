{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5513, 4) (2363, 4) (5513,) (2363,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 경향성이 있는 그래프의 선형적으로 증가할 수 있게 하는 함수 \n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "# x: 시간축인 함수 plot 함수\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14)\n",
    "    plt.grid(True)\n",
    "\n",
    "# 120개씩 자르는 함수 \n",
    "def univariate_data(dataset, start_index, end_index):\n",
    "    data = []\n",
    "    history_size = 120\n",
    "    start_index = start_index + history_size\n",
    "\n",
    "\n",
    "    for i in range(start_index, end_index, 120): # 0\n",
    "        indices = range(i - history_size, i) # [0 - 120] , [120 - 240] ...\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "for i in range(1,9):\n",
    "    globals()['df_'+str(i) ]= pd.read_csv('./temperature_csv_file/temp_df_{}.csv'.format(i), encoding = 'cp949')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2], axis = 0)\n",
    "df_all = pd.concat([df_all, df_3], axis = 0)\n",
    "df_all = pd.concat([df_all, df_4], axis = 0)\n",
    "df_all = pd.concat([df_all, df_5], axis = 0)\n",
    "df_all = pd.concat([df_all, df_6], axis = 0)\n",
    "df_all = pd.concat([df_all, df_7], axis = 0)\n",
    "df_all = pd.concat([df_all, df_8], axis = 0)\n",
    "\n",
    "df_all = df_all[:601800].reset_index().drop(columns = ['index'], axis = 0)\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_tmp'] = df_all[85920*(i-1):85920*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_tmp']['TEMP'].mean()\n",
    "    diff  = 261.7292228119181 - mean\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_tmp'] = globals()['df_'+str(i-5)+'_tmp'].copy()\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_tmp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_tmp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(85920)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_tmp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] = series\n",
    "\n",
    "\n",
    "univariate_past_history = 120\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : [], 'batch_num' : []}\n",
    "\n",
    "    for j in range(716):\n",
    "        MEAN = np.round(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].mean(),3)\n",
    "        MIN = np.min(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        MAX = np.max(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        STD = np.std(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        skew = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].skew()\n",
    "        kurt = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].kurt()\n",
    "        median = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].median()\n",
    "        data[0], data[1] = np.percentile(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)], q=[25,75])\n",
    "        data['Group'].append(i)\n",
    "        data['batch_num'].append(j+1)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(data[0],3))\n",
    "        data['75%'].append(np.round(data[1],3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(7876)})\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index',0,1], inplace = True)\n",
    "df = tmp\n",
    "\n",
    "for i in range(1,12):\n",
    "    globals()['df_temp_'+str(i)] = univariate_data(globals()['df_'+str(i)+'_tmp']['TEMP'], 0, len(df_1_tmp)+1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.iloc[:, :9].values\n",
    "X_mean = df['MEAN_TEMP'].values\n",
    "y = df['Group'].values - 1\n",
    "X_mean = X_mean.reshape(X_mean.shape[0], 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_mean_scale = scaler.fit_transform(X_mean)\n",
    "e = LabelEncoder()\n",
    "Y = e.fit_transform(y)\n",
    "Y = tf.keras.utils.to_categorical(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
