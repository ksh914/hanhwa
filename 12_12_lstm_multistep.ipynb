{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m날짜파일\u001b[0m/\n",
      "\u001b[01;34m참조파일\u001b[0m/\n",
      "11_29_lstm_single.ipynb\n",
      "11_29_trans_single.ipynb\n",
      "12_12_lstm_multistep.ipynb\n",
      "\u001b[01;34m모의csv파일\u001b[0m/\n",
      "deep_learning.ipynb\n",
      "\u001b[01;34mfunction_file\u001b[0m/\n",
      "lstm_multivariate_prediction_12_04.ipynb\n",
      "lstm_test.ipynb\n",
      "machine_learning.ipynb\n",
      "\u001b[01;34mmodel\u001b[0m/\n",
      "\u001b[01;34mnew_temp_file\u001b[0m/\n",
      "README.md\n",
      "requirements.txt\n",
      "\u001b[01;34mtemp_add_gps\u001b[0m/\n",
      "\u001b[01;34mtemperature_csv_file\u001b[0m/\n",
      "\u001b[01;34mtmp\u001b[0m/\n",
      "transformer_multivariate_prediction_12_05.ipynb\n",
      "transformer_multivarite_prediction.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function_file as ff\n",
    "from function_file.time_series import time_series_dataframe\n",
    "df = time_series_dataframe()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy as dc\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "def multistep_time_series(input_data, input_window, output_window):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-input_window):\n",
    "        train_seq = np.append(input_data[i:i+input_window][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+input_window]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = df['TEMP'].values\n",
    "train_len = int(len(df) * 0.7)\n",
    "train = df[:train_len]\n",
    "test = df[train_len:]\n",
    "input_window =100\n",
    "output_window = 60\n",
    "\n",
    "train_data = multistep_time_series(train, input_window, output_window)\n",
    "test_data = multistep_time_series(test, input_window, output_window)\n",
    "train_data = train_data[:-output_window]\n",
    "test_data = test_data[:-output_window]\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 512\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LSTM_ms(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super(LSTM_ms, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from helper import series_to_supervised, mean_absolute_percentage_error\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(65, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(train_y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
