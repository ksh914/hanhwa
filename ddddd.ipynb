{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 경향성이 있는 그래프의 선형적으로 증가할 수 있게 하는 함수 \n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "# x: 시간축인 함수 plot 함수\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14)\n",
    "    plt.grid(True)\n",
    "\n",
    "# 120개씩 자르는 함수 \n",
    "def univariate_data(dataset, start_index, end_index):\n",
    "    data = []\n",
    "    history_size = 120\n",
    "    start_index = start_index + history_size\n",
    "\n",
    "\n",
    "    for i in range(start_index, end_index, 120): # 0\n",
    "        indices = range(i - history_size, i) # [0 - 120] , [120 - 240] ...\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "for i in range(1,9):\n",
    "    globals()['df_'+str(i) ]= pd.read_csv('./temperature_csv_file/temp_df_{}.csv'.format(i), encoding = 'cp949')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2], axis = 0)\n",
    "df_all = pd.concat([df_all, df_3], axis = 0)\n",
    "df_all = pd.concat([df_all, df_4], axis = 0)\n",
    "df_all = pd.concat([df_all, df_5], axis = 0)\n",
    "df_all = pd.concat([df_all, df_6], axis = 0)\n",
    "df_all = pd.concat([df_all, df_7], axis = 0)\n",
    "df_all = pd.concat([df_all, df_8], axis = 0)\n",
    "\n",
    "df_all = df_all[:601800].reset_index().drop(columns = ['index'], axis = 0)\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_tmp'] = df_all[85920*(i-1):85920*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_tmp']['TEMP'].mean()\n",
    "    diff  = 261.7292228119181 - mean\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_tmp'] = globals()['df_'+str(i-5)+'_tmp'].copy()\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_tmp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_tmp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(85920)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_tmp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] = series\n",
    "\n",
    "\n",
    "univariate_past_history = 120\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(716):\n",
    "        MEAN = np.round(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].mean(),3)\n",
    "        MIN = np.min(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        MAX = np.max(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        STD = np.std(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        skew = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].skew()\n",
    "        kurt = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].kurt()\n",
    "        median = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].median()\n",
    "        a, b = np.percentile(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)], q=[25,75])\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(7876)})\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286.797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287.082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285.938</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285.772</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286.357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945115</th>\n",
       "      <td>933.812</td>\n",
       "      <td>945115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945116</th>\n",
       "      <td>934.304</td>\n",
       "      <td>945116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945117</th>\n",
       "      <td>934.530</td>\n",
       "      <td>945117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945118</th>\n",
       "      <td>934.443</td>\n",
       "      <td>945118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945119</th>\n",
       "      <td>934.625</td>\n",
       "      <td>945119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEMP    TIME\n",
       "0       286.797       0\n",
       "1       287.082       1\n",
       "2       285.938       2\n",
       "3       285.772       3\n",
       "4       286.357       4\n",
       "...         ...     ...\n",
       "945115  933.812  945115\n",
       "945116  934.304  945116\n",
       "945117  934.530  945117\n",
       "945118  934.443  945118\n",
       "945119  934.625  945119\n",
       "\n",
       "[945120 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_tmp'] = df_all[85920*(i-1):85920*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_tmp']['TEMP'].mean()\n",
    "    diff  = 261.7292228119181 - mean\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_tmp'] = globals()['df_'+str(i-5)+'_tmp'].copy()\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_tmp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] = series\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(0,85890,30):\n",
    "        temp = globals()['df_'+str(i)+'_tmp']['TEMP'][j:j+60]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(len(group_1))\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(31493)})\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df = tmp\n",
    "df\n",
    "\n",
    "tmp = np.arange(945120)\n",
    "TIME = pd.DataFrame({'TIME' : tmp})\n",
    "df_temp_all = pd.concat([df_1_tmp, df_2_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_3_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_4_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_5_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_6_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_7_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_8_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_9_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_10_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_11_tmp], axis = 0)\n",
    "df_temp_all = df_temp_all.reset_index().drop(columns = ['date', 'index','kst'])\n",
    "df_temp_all = pd.concat([df_temp_all,TIME], axis = 1)\n",
    "df_temp_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[287.0820, 285.9380, 285.7720,  ..., 285.4390, 285.4070, 285.0360],\n",
       "        [283.3250, 283.0740, 283.2020,  ..., 283.8140, 283.7250, 284.1280],\n",
       "        [284.6300, 283.4610, 282.9700,  ..., 282.9600, 283.2180, 283.8060],\n",
       "        ...,\n",
       "        [796.2500, 796.7820, 797.1760,  ..., 798.8010, 798.7430, 798.9550],\n",
       "        [798.5650, 798.5220, 798.1570,  ..., 798.0420, 798.1020, 798.0210],\n",
       "        [798.8800, 798.8490, 798.9590,  ..., 798.6030, 798.8490, 799.2560]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    " \n",
    "\n",
    "timeseries = df_temp_all['TEMP'].values.astype('float32')\n",
    " \n",
    "# train-test split for time series\n",
    "train_size = int(len(timeseries) * 0.8)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]\n",
    " \n",
    "def create_dataset(dataset, lookback,stride):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "        stride : how amny stride do you want to jump\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(0,len(dataset)-lookback, stride):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    " \n",
    "lookback = 60\n",
    "X_train, y_train = create_dataset(train, lookback=lookback, stride = 30)\n",
    "X_test, y_test = create_dataset(test, lookback=lookback, stride = 30)\n",
    "\n",
    "# class DATA(data.Dataset):\n",
    "\n",
    "#     def __init__(self,lookback, stride):\n",
    "#         self.lookback = lookback\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "#         return \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=16, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(16, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    " \n",
    "model = AirModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=512)\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    if epoch % 100 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # shift train predictions for plotting\n",
    "    train_plot = np.ones_like(timeseries) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    y_pred = y_pred[:, -1, :]\n",
    "    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(timeseries) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n",
    "# plot\n",
    "plt.plot(timeseries)\n",
    "plt.plot(train_plot, c='r')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
