{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'function_file' from 'c:\\\\Users\\\\Sejong\\\\Desktop\\\\hanhwa\\\\function_file\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import function_file as ff\n",
    "import importlib\n",
    "importlib.reload(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "      <th>label</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286.797</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287.082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285.938</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285.772</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286.357</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664791</th>\n",
       "      <td>865.029</td>\n",
       "      <td>11</td>\n",
       "      <td>664791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664792</th>\n",
       "      <td>864.985</td>\n",
       "      <td>11</td>\n",
       "      <td>664792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664793</th>\n",
       "      <td>865.048</td>\n",
       "      <td>11</td>\n",
       "      <td>664793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664794</th>\n",
       "      <td>865.040</td>\n",
       "      <td>11</td>\n",
       "      <td>664794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664795</th>\n",
       "      <td>864.972</td>\n",
       "      <td>11</td>\n",
       "      <td>664795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEMP  label    TIME\n",
       "0       286.797      1       0\n",
       "1       287.082      1       1\n",
       "2       285.938      1       2\n",
       "3       285.772      1       3\n",
       "4       286.357      1       4\n",
       "...         ...    ...     ...\n",
       "664791  865.029     11  664791\n",
       "664792  864.985     11  664792\n",
       "664793  865.048     11  664793\n",
       "664794  865.040     11  664794\n",
       "664795  864.972     11  664795\n",
       "\n",
       "[664796 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from function_file.time_series import time_series_dataframe\n",
    "data = time_series_dataframe()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as dc\n",
    "def prepare_dataframe_for_lstm(df, lookback_size,output_size):\n",
    "    df = dc(df)\n",
    "    \n",
    "    for i in range(1,lookback_size+1):\n",
    "        df[f'TEMP(t-{i})'] = df['TEMP'].shift(i)\n",
    "\n",
    "    for j in range(1,output_size + 1):\n",
    "        df[f'TEMP(t+{j})'] = df['TEMP'].shift(-j)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def multi_step_LSTM(df, lookback_size, output_size, batch_size):\n",
    "    shifted_df = prepare_dataframe_for_lstm(df, lookback_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     286.797\n",
       "1     287.082\n",
       "2     285.938\n",
       "3     285.772\n",
       "4     286.357\n",
       "5     286.277\n",
       "6     285.319\n",
       "7     285.025\n",
       "8     284.926\n",
       "9     285.140\n",
       "10    285.599\n",
       "11    285.847\n",
       "12    286.690\n",
       "13    286.455\n",
       "14    286.533\n",
       "15    286.373\n",
       "16    286.309\n",
       "17    285.839\n",
       "18    284.966\n",
       "19    284.483\n",
       "20    283.768\n",
       "21    283.232\n",
       "22    283.285\n",
       "23    283.050\n",
       "24    282.631\n",
       "25    282.050\n",
       "26    281.668\n",
       "27    281.817\n",
       "28    281.401\n",
       "29    282.002\n",
       "30    282.623\n",
       "31    283.325\n",
       "32    283.074\n",
       "33    283.202\n",
       "34    283.739\n",
       "35    284.014\n",
       "36    283.416\n",
       "37    282.663\n",
       "38    282.306\n",
       "39    282.719\n",
       "Name: TEMP, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TEMP'][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEMP', 'TEMP(t-1)', 'TEMP(t-2)', 'TEMP(t-3)', 'TEMP(t-4)', 'TEMP(t-5)',\n",
       "       'TEMP(t-6)', 'TEMP(t-7)', 'TEMP(t-8)', 'TEMP(t-9)', 'TEMP(t-10)',\n",
       "       'TEMP(t-11)', 'TEMP(t-12)', 'TEMP(t-13)', 'TEMP(t-14)', 'TEMP(t-15)',\n",
       "       'TEMP(t-16)', 'TEMP(t-17)', 'TEMP(t-18)', 'TEMP(t-19)', 'TEMP(t-20)',\n",
       "       'TEMP(t-21)', 'TEMP(t-22)', 'TEMP(t-23)', 'TEMP(t-24)', 'TEMP(t-25)',\n",
       "       'TEMP(t-26)', 'TEMP(t-27)', 'TEMP(t-28)', 'TEMP(t-29)', 'TEMP(t-30)',\n",
       "       'TEMP(t+1)', 'TEMP(t+2)', 'TEMP(t+3)', 'TEMP(t+4)', 'TEMP(t+5)',\n",
       "       'TEMP(t+6)', 'TEMP(t+7)', 'TEMP(t+8)', 'TEMP(t+9)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = data['TEMP']\n",
    "train_len = int(len(df) * 0.8)\n",
    "\n",
    "shifted_df = prepare_dataframe_for_lstm(data, 30,9)\n",
    "shifted_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMP(t-1)</th>\n",
       "      <th>TEMP(t-2)</th>\n",
       "      <th>TEMP(t-3)</th>\n",
       "      <th>TEMP(t-4)</th>\n",
       "      <th>TEMP(t-5)</th>\n",
       "      <th>TEMP(t-6)</th>\n",
       "      <th>TEMP(t-7)</th>\n",
       "      <th>TEMP(t-8)</th>\n",
       "      <th>TEMP(t-9)</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMP(t-30)</th>\n",
       "      <th>TEMP(t+1)</th>\n",
       "      <th>TEMP(t+2)</th>\n",
       "      <th>TEMP(t+3)</th>\n",
       "      <th>TEMP(t+4)</th>\n",
       "      <th>TEMP(t+5)</th>\n",
       "      <th>TEMP(t+6)</th>\n",
       "      <th>TEMP(t+7)</th>\n",
       "      <th>TEMP(t+8)</th>\n",
       "      <th>TEMP(t+9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>282.623</td>\n",
       "      <td>282.002</td>\n",
       "      <td>281.401</td>\n",
       "      <td>281.817</td>\n",
       "      <td>281.668</td>\n",
       "      <td>282.050</td>\n",
       "      <td>282.631</td>\n",
       "      <td>283.050</td>\n",
       "      <td>283.285</td>\n",
       "      <td>283.232</td>\n",
       "      <td>...</td>\n",
       "      <td>286.797</td>\n",
       "      <td>283.325</td>\n",
       "      <td>283.074</td>\n",
       "      <td>283.202</td>\n",
       "      <td>283.739</td>\n",
       "      <td>284.014</td>\n",
       "      <td>283.416</td>\n",
       "      <td>282.663</td>\n",
       "      <td>282.306</td>\n",
       "      <td>282.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>283.325</td>\n",
       "      <td>282.623</td>\n",
       "      <td>282.002</td>\n",
       "      <td>281.401</td>\n",
       "      <td>281.817</td>\n",
       "      <td>281.668</td>\n",
       "      <td>282.050</td>\n",
       "      <td>282.631</td>\n",
       "      <td>283.050</td>\n",
       "      <td>283.285</td>\n",
       "      <td>...</td>\n",
       "      <td>287.082</td>\n",
       "      <td>283.074</td>\n",
       "      <td>283.202</td>\n",
       "      <td>283.739</td>\n",
       "      <td>284.014</td>\n",
       "      <td>283.416</td>\n",
       "      <td>282.663</td>\n",
       "      <td>282.306</td>\n",
       "      <td>282.719</td>\n",
       "      <td>283.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>283.074</td>\n",
       "      <td>283.325</td>\n",
       "      <td>282.623</td>\n",
       "      <td>282.002</td>\n",
       "      <td>281.401</td>\n",
       "      <td>281.817</td>\n",
       "      <td>281.668</td>\n",
       "      <td>282.050</td>\n",
       "      <td>282.631</td>\n",
       "      <td>283.050</td>\n",
       "      <td>...</td>\n",
       "      <td>285.938</td>\n",
       "      <td>283.202</td>\n",
       "      <td>283.739</td>\n",
       "      <td>284.014</td>\n",
       "      <td>283.416</td>\n",
       "      <td>282.663</td>\n",
       "      <td>282.306</td>\n",
       "      <td>282.719</td>\n",
       "      <td>283.085</td>\n",
       "      <td>283.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>283.202</td>\n",
       "      <td>283.074</td>\n",
       "      <td>283.325</td>\n",
       "      <td>282.623</td>\n",
       "      <td>282.002</td>\n",
       "      <td>281.401</td>\n",
       "      <td>281.817</td>\n",
       "      <td>281.668</td>\n",
       "      <td>282.050</td>\n",
       "      <td>282.631</td>\n",
       "      <td>...</td>\n",
       "      <td>285.772</td>\n",
       "      <td>283.739</td>\n",
       "      <td>284.014</td>\n",
       "      <td>283.416</td>\n",
       "      <td>282.663</td>\n",
       "      <td>282.306</td>\n",
       "      <td>282.719</td>\n",
       "      <td>283.085</td>\n",
       "      <td>283.210</td>\n",
       "      <td>283.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>283.739</td>\n",
       "      <td>283.202</td>\n",
       "      <td>283.074</td>\n",
       "      <td>283.325</td>\n",
       "      <td>282.623</td>\n",
       "      <td>282.002</td>\n",
       "      <td>281.401</td>\n",
       "      <td>281.817</td>\n",
       "      <td>281.668</td>\n",
       "      <td>282.050</td>\n",
       "      <td>...</td>\n",
       "      <td>286.357</td>\n",
       "      <td>284.014</td>\n",
       "      <td>283.416</td>\n",
       "      <td>282.663</td>\n",
       "      <td>282.306</td>\n",
       "      <td>282.719</td>\n",
       "      <td>283.085</td>\n",
       "      <td>283.210</td>\n",
       "      <td>283.328</td>\n",
       "      <td>283.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664782</th>\n",
       "      <td>864.925</td>\n",
       "      <td>864.918</td>\n",
       "      <td>864.969</td>\n",
       "      <td>865.039</td>\n",
       "      <td>865.006</td>\n",
       "      <td>864.970</td>\n",
       "      <td>864.981</td>\n",
       "      <td>865.008</td>\n",
       "      <td>865.005</td>\n",
       "      <td>864.955</td>\n",
       "      <td>...</td>\n",
       "      <td>864.795</td>\n",
       "      <td>864.884</td>\n",
       "      <td>864.910</td>\n",
       "      <td>864.968</td>\n",
       "      <td>864.988</td>\n",
       "      <td>865.035</td>\n",
       "      <td>864.874</td>\n",
       "      <td>864.940</td>\n",
       "      <td>865.003</td>\n",
       "      <td>865.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664783</th>\n",
       "      <td>864.884</td>\n",
       "      <td>864.925</td>\n",
       "      <td>864.918</td>\n",
       "      <td>864.969</td>\n",
       "      <td>865.039</td>\n",
       "      <td>865.006</td>\n",
       "      <td>864.970</td>\n",
       "      <td>864.981</td>\n",
       "      <td>865.008</td>\n",
       "      <td>865.005</td>\n",
       "      <td>...</td>\n",
       "      <td>864.757</td>\n",
       "      <td>864.910</td>\n",
       "      <td>864.968</td>\n",
       "      <td>864.988</td>\n",
       "      <td>865.035</td>\n",
       "      <td>864.874</td>\n",
       "      <td>864.940</td>\n",
       "      <td>865.003</td>\n",
       "      <td>865.029</td>\n",
       "      <td>864.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664784</th>\n",
       "      <td>864.910</td>\n",
       "      <td>864.884</td>\n",
       "      <td>864.925</td>\n",
       "      <td>864.918</td>\n",
       "      <td>864.969</td>\n",
       "      <td>865.039</td>\n",
       "      <td>865.006</td>\n",
       "      <td>864.970</td>\n",
       "      <td>864.981</td>\n",
       "      <td>865.008</td>\n",
       "      <td>...</td>\n",
       "      <td>864.811</td>\n",
       "      <td>864.968</td>\n",
       "      <td>864.988</td>\n",
       "      <td>865.035</td>\n",
       "      <td>864.874</td>\n",
       "      <td>864.940</td>\n",
       "      <td>865.003</td>\n",
       "      <td>865.029</td>\n",
       "      <td>864.985</td>\n",
       "      <td>865.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664785</th>\n",
       "      <td>864.968</td>\n",
       "      <td>864.910</td>\n",
       "      <td>864.884</td>\n",
       "      <td>864.925</td>\n",
       "      <td>864.918</td>\n",
       "      <td>864.969</td>\n",
       "      <td>865.039</td>\n",
       "      <td>865.006</td>\n",
       "      <td>864.970</td>\n",
       "      <td>864.981</td>\n",
       "      <td>...</td>\n",
       "      <td>865.005</td>\n",
       "      <td>864.988</td>\n",
       "      <td>865.035</td>\n",
       "      <td>864.874</td>\n",
       "      <td>864.940</td>\n",
       "      <td>865.003</td>\n",
       "      <td>865.029</td>\n",
       "      <td>864.985</td>\n",
       "      <td>865.048</td>\n",
       "      <td>865.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664786</th>\n",
       "      <td>864.988</td>\n",
       "      <td>864.968</td>\n",
       "      <td>864.910</td>\n",
       "      <td>864.884</td>\n",
       "      <td>864.925</td>\n",
       "      <td>864.918</td>\n",
       "      <td>864.969</td>\n",
       "      <td>865.039</td>\n",
       "      <td>865.006</td>\n",
       "      <td>864.970</td>\n",
       "      <td>...</td>\n",
       "      <td>865.085</td>\n",
       "      <td>865.035</td>\n",
       "      <td>864.874</td>\n",
       "      <td>864.940</td>\n",
       "      <td>865.003</td>\n",
       "      <td>865.029</td>\n",
       "      <td>864.985</td>\n",
       "      <td>865.048</td>\n",
       "      <td>865.040</td>\n",
       "      <td>864.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664757 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEMP  TEMP(t-1)  TEMP(t-2)  TEMP(t-3)  TEMP(t-4)  TEMP(t-5)  \\\n",
       "30      282.623    282.002    281.401    281.817    281.668    282.050   \n",
       "31      283.325    282.623    282.002    281.401    281.817    281.668   \n",
       "32      283.074    283.325    282.623    282.002    281.401    281.817   \n",
       "33      283.202    283.074    283.325    282.623    282.002    281.401   \n",
       "34      283.739    283.202    283.074    283.325    282.623    282.002   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "664782  864.925    864.918    864.969    865.039    865.006    864.970   \n",
       "664783  864.884    864.925    864.918    864.969    865.039    865.006   \n",
       "664784  864.910    864.884    864.925    864.918    864.969    865.039   \n",
       "664785  864.968    864.910    864.884    864.925    864.918    864.969   \n",
       "664786  864.988    864.968    864.910    864.884    864.925    864.918   \n",
       "\n",
       "        TEMP(t-6)  TEMP(t-7)  TEMP(t-8)  TEMP(t-9)  ...  TEMP(t-30)  \\\n",
       "30        282.631    283.050    283.285    283.232  ...     286.797   \n",
       "31        282.050    282.631    283.050    283.285  ...     287.082   \n",
       "32        281.668    282.050    282.631    283.050  ...     285.938   \n",
       "33        281.817    281.668    282.050    282.631  ...     285.772   \n",
       "34        281.401    281.817    281.668    282.050  ...     286.357   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "664782    864.981    865.008    865.005    864.955  ...     864.795   \n",
       "664783    864.970    864.981    865.008    865.005  ...     864.757   \n",
       "664784    865.006    864.970    864.981    865.008  ...     864.811   \n",
       "664785    865.039    865.006    864.970    864.981  ...     865.005   \n",
       "664786    864.969    865.039    865.006    864.970  ...     865.085   \n",
       "\n",
       "        TEMP(t+1)  TEMP(t+2)  TEMP(t+3)  TEMP(t+4)  TEMP(t+5)  TEMP(t+6)  \\\n",
       "30        283.325    283.074    283.202    283.739    284.014    283.416   \n",
       "31        283.074    283.202    283.739    284.014    283.416    282.663   \n",
       "32        283.202    283.739    284.014    283.416    282.663    282.306   \n",
       "33        283.739    284.014    283.416    282.663    282.306    282.719   \n",
       "34        284.014    283.416    282.663    282.306    282.719    283.085   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "664782    864.884    864.910    864.968    864.988    865.035    864.874   \n",
       "664783    864.910    864.968    864.988    865.035    864.874    864.940   \n",
       "664784    864.968    864.988    865.035    864.874    864.940    865.003   \n",
       "664785    864.988    865.035    864.874    864.940    865.003    865.029   \n",
       "664786    865.035    864.874    864.940    865.003    865.029    864.985   \n",
       "\n",
       "        TEMP(t+7)  TEMP(t+8)  TEMP(t+9)  \n",
       "30        282.663    282.306    282.719  \n",
       "31        282.306    282.719    283.085  \n",
       "32        282.719    283.085    283.210  \n",
       "33        283.085    283.210    283.328  \n",
       "34        283.210    283.328    283.656  \n",
       "...           ...        ...        ...  \n",
       "664782    864.940    865.003    865.029  \n",
       "664783    865.003    865.029    864.985  \n",
       "664784    865.029    864.985    865.048  \n",
       "664785    864.985    865.048    865.040  \n",
       "664786    865.048    865.040    864.972  \n",
       "\n",
       "[664757 rows x 40 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "y = pd.concat([shifted_df.iloc[:, 0], shifted_df.iloc[:, 31:]], axis = 1)\n",
    "X = shifted_df.iloc[:, 1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((664757, 30), (664757, 10))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((531805, 30), (531805, 10), (132952, 30), (132952, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = int(len(X) * 0.8)\n",
    "X_train = X[:train_len]\n",
    "y_train = y[:train_len]\n",
    "\n",
    "X_test = X[train_len:]\n",
    "y_test = y[train_len:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lookback_size = 30\n",
    "output_size = 10\n",
    "X_train = X_train.reshape((-1,lookback_size,1))\n",
    "X_test = X_test.reshape((-1,lookback_size, 1))\n",
    "y_train = y_train.reshape((-1, output_size, 1))\n",
    "y_test = y_test.reshape((-1, output_size, 1))\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "y_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(1,4,1).to(device)\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "criterion = nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        training_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    A, B = batch[0].to(device), batch[1].to(device)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 30, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A.shape)\n",
    "model = LSTM(1,4,1).to(device)\n",
    "output = model(A)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([512, 10, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\lstm_multivariate_prediction_12_04.ipynb 셀 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train()\n",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\lstm_multivariate_prediction_12_04.ipynb 셀 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_batch, y_batch \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m model(X_batch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/lstm_multivariate_prediction_12_04.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 535\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\functional.py:3328\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3325\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3326\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3328\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3329\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for i in range(10):\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
