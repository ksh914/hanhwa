{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMP</th>\n",
       "      <th>STD</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURT</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Group</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285.886</td>\n",
       "      <td>0.703473</td>\n",
       "      <td>284.483</td>\n",
       "      <td>287.082</td>\n",
       "      <td>-0.295420</td>\n",
       "      <td>-0.875405</td>\n",
       "      <td>285.893</td>\n",
       "      <td>285.274</td>\n",
       "      <td>286.394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283.442</td>\n",
       "      <td>1.447050</td>\n",
       "      <td>281.401</td>\n",
       "      <td>286.373</td>\n",
       "      <td>0.750285</td>\n",
       "      <td>-0.205477</td>\n",
       "      <td>283.217</td>\n",
       "      <td>282.480</td>\n",
       "      <td>283.947</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283.295</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>282.306</td>\n",
       "      <td>284.014</td>\n",
       "      <td>-0.567776</td>\n",
       "      <td>-0.220987</td>\n",
       "      <td>283.327</td>\n",
       "      <td>283.082</td>\n",
       "      <td>283.642</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283.934</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>282.952</td>\n",
       "      <td>285.439</td>\n",
       "      <td>0.761031</td>\n",
       "      <td>-0.745803</td>\n",
       "      <td>283.649</td>\n",
       "      <td>283.322</td>\n",
       "      <td>284.548</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283.616</td>\n",
       "      <td>0.676819</td>\n",
       "      <td>282.463</td>\n",
       "      <td>285.036</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.099465</td>\n",
       "      <td>283.514</td>\n",
       "      <td>283.180</td>\n",
       "      <td>283.875</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53873</th>\n",
       "      <td>859.469</td>\n",
       "      <td>0.069259</td>\n",
       "      <td>859.259</td>\n",
       "      <td>859.599</td>\n",
       "      <td>-1.694207</td>\n",
       "      <td>4.534614</td>\n",
       "      <td>859.478</td>\n",
       "      <td>859.464</td>\n",
       "      <td>859.493</td>\n",
       "      <td>11</td>\n",
       "      <td>53873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53874</th>\n",
       "      <td>859.483</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>859.055</td>\n",
       "      <td>859.769</td>\n",
       "      <td>-0.407907</td>\n",
       "      <td>-0.315194</td>\n",
       "      <td>859.477</td>\n",
       "      <td>859.378</td>\n",
       "      <td>859.658</td>\n",
       "      <td>11</td>\n",
       "      <td>53874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53875</th>\n",
       "      <td>858.899</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.465</td>\n",
       "      <td>-0.029760</td>\n",
       "      <td>-1.518960</td>\n",
       "      <td>858.917</td>\n",
       "      <td>858.602</td>\n",
       "      <td>859.247</td>\n",
       "      <td>11</td>\n",
       "      <td>53875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53876</th>\n",
       "      <td>859.058</td>\n",
       "      <td>0.262727</td>\n",
       "      <td>858.522</td>\n",
       "      <td>859.522</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>-0.418698</td>\n",
       "      <td>858.999</td>\n",
       "      <td>858.941</td>\n",
       "      <td>859.286</td>\n",
       "      <td>11</td>\n",
       "      <td>53876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53877</th>\n",
       "      <td>858.892</td>\n",
       "      <td>0.094946</td>\n",
       "      <td>858.717</td>\n",
       "      <td>858.998</td>\n",
       "      <td>-0.735253</td>\n",
       "      <td>-0.339341</td>\n",
       "      <td>858.907</td>\n",
       "      <td>858.835</td>\n",
       "      <td>858.975</td>\n",
       "      <td>11</td>\n",
       "      <td>53877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53878 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       "0        285.886  0.703473  284.483  287.082 -0.295420 -0.875405  285.893   \n",
       "1        283.442  1.447050  281.401  286.373  0.750285 -0.205477  283.217   \n",
       "2        283.295  0.440360  282.306  284.014 -0.567776 -0.220987  283.327   \n",
       "3        283.934  0.786485  282.952  285.439  0.761031 -0.745803  283.649   \n",
       "4        283.616  0.676819  282.463  285.036  0.524393  0.099465  283.514   \n",
       "...          ...       ...      ...      ...       ...       ...      ...   \n",
       "53873    859.469  0.069259  859.259  859.599 -1.694207  4.534614  859.478   \n",
       "53874    859.483  0.195625  859.055  859.769 -0.407907 -0.315194  859.477   \n",
       "53875    858.899  0.373143  858.337  859.465 -0.029760 -1.518960  858.917   \n",
       "53876    859.058  0.262727  858.522  859.522  0.008027 -0.418698  858.999   \n",
       "53877    858.892  0.094946  858.717  858.998 -0.735253 -0.339341  858.907   \n",
       "\n",
       "           25%      75%  Group   TIME  \n",
       "0      285.274  286.394      1      0  \n",
       "1      282.480  283.947      1      1  \n",
       "2      283.082  283.642      1      2  \n",
       "3      283.322  284.548      1      3  \n",
       "4      283.180  283.875      1      4  \n",
       "...        ...      ...    ...    ...  \n",
       "53873  859.464  859.493     11  53873  \n",
       "53874  859.378  859.658     11  53874  \n",
       "53875  858.602  859.247     11  53875  \n",
       "53876  858.941  859.286     11  53876  \n",
       "53877  858.835  858.975     11  53877  \n",
       "\n",
       "[53878 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./new_temp_file/temperature_time')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_temp'] = df[73462*(i-1):73462*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_temp']['TEMP'].mean()\n",
    "    diff  = 283.733148 - mean\n",
    "    globals()['df_'+str(i)+'_temp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_temp'] = globals()['df_'+str(i-5)+'_temp'].copy()\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_temp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_temp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(73462)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_temp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_temp']['TEMP'] = series\n",
    "\n",
    "df_temp_all = pd.concat([df_1_temp, df_2_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_3_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_4_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_5_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_6_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_7_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_8_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_9_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_10_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_11_temp], axis = 0)\n",
    "df_temp_all = df_temp_all.reset_index().drop(columns=['index','TIME'])\n",
    "tmp = np.arange(808082)\n",
    "TIME = pd.DataFrame({'TIME' : tmp})\n",
    "df_temp_all = pd.concat([df_temp_all, TIME], axis = 1)\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(0,73462,15):\n",
    "        temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+20]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df_9_cols = tmp\n",
    "df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "df_9_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def THRESHOLD(data):\n",
    "    if data>=797.314:\n",
    "        return 11\n",
    "    elif data>=740.9375:\n",
    "        return 10\n",
    "    elif data>=684.5565:\n",
    "        return 9\n",
    "    elif data>=628.1795:\n",
    "        return 8\n",
    "    elif data>=571.7965:\n",
    "        return 7\n",
    "    elif data>=515.4215:\n",
    "        return 6\n",
    "    elif data>=459.045:\n",
    "        return 5\n",
    "    elif data>=402.6645:\n",
    "        return 4\n",
    "    elif data>=346.28:\n",
    "        return 3\n",
    "    elif data>=289/9025:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5\n",
      "(129289, 9) (32323, 9) (129289,) (32323,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 129289, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.395817\n",
      "[LightGBM] [Info] Start training from score -2.400412\n",
      "[LightGBM] [Info] Start training from score -2.395732\n",
      "[LightGBM] [Info] Start training from score -2.393188\n",
      "[LightGBM] [Info] Start training from score -2.397686\n",
      "[LightGBM] [Info] Start training from score -2.401692\n",
      "[LightGBM] [Info] Start training from score -2.395987\n",
      "[LightGBM] [Info] Start training from score -2.394374\n",
      "[LightGBM] [Info] Start training from score -2.400242\n",
      "[LightGBM] [Info] Start training from score -2.402205\n",
      "[LightGBM] [Info] Start training from score -2.399560\n",
      "LGBM  0.7782074683661789\n",
      "KN 0.7661726943662408\n",
      "DTC 0.731708071651765\n",
      "RFC 0.7929028864894967\n",
      "0.5287540529168626\n",
      "10 3\n",
      "(215485, 9) (53872, 9) (215485,) (53872,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 215485, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.396801\n",
      "[LightGBM] [Info] Start training from score -2.397413\n",
      "[LightGBM] [Info] Start training from score -2.399251\n",
      "[LightGBM] [Info] Start training from score -2.398740\n",
      "[LightGBM] [Info] Start training from score -2.396699\n",
      "[LightGBM] [Info] Start training from score -2.397158\n",
      "[LightGBM] [Info] Start training from score -2.399047\n",
      "[LightGBM] [Info] Start training from score -2.398178\n",
      "[LightGBM] [Info] Start training from score -2.399302\n",
      "[LightGBM] [Info] Start training from score -2.403195\n",
      "[LightGBM] [Info] Start training from score -2.391106\n",
      "LGBM  0.7816676566676567\n",
      "KN 0.7757090882090882\n",
      "DTC 0.7565896940896941\n",
      "RFC 0.8105880605880605\n",
      "0.5286886919589987\n",
      "20 10\n",
      "(64644, 9) (16162, 9) (64644,) (16162,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 64644, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.389040\n",
      "[LightGBM] [Info] Start training from score -2.399893\n",
      "[LightGBM] [Info] Start training from score -2.394960\n",
      "[LightGBM] [Info] Start training from score -2.398870\n",
      "[LightGBM] [Info] Start training from score -2.394452\n",
      "[LightGBM] [Info] Start training from score -2.395639\n",
      "[LightGBM] [Info] Start training from score -2.414492\n",
      "[LightGBM] [Info] Start training from score -2.395470\n",
      "[LightGBM] [Info] Start training from score -2.393096\n",
      "[LightGBM] [Info] Start training from score -2.403138\n",
      "[LightGBM] [Info] Start training from score -2.398019\n",
      "LGBM  0.7921049375077341\n",
      "KN 0.7783071402054201\n",
      "DTC 0.7564657839376315\n",
      "RFC 0.8112238584333622\n",
      "0.5289334950374972\n",
      "20 6\n",
      "(107747, 9) (26937, 9) (107747,) (26937,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 107747, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.392314\n",
      "[LightGBM] [Info] Start training from score -2.401391\n",
      "[LightGBM] [Info] Start training from score -2.401596\n",
      "[LightGBM] [Info] Start training from score -2.392213\n",
      "[LightGBM] [Info] Start training from score -2.401698\n",
      "[LightGBM] [Info] Start training from score -2.395161\n",
      "[LightGBM] [Info] Start training from score -2.395568\n",
      "[LightGBM] [Info] Start training from score -2.400674\n",
      "[LightGBM] [Info] Start training from score -2.396689\n",
      "[LightGBM] [Info] Start training from score -2.401596\n",
      "[LightGBM] [Info] Start training from score -2.398016\n",
      "LGBM  0.8027620002227419\n",
      "KN 0.7978245535880016\n",
      "DTC 0.7860192300553143\n",
      "RFC 0.8391431859524074\n",
      "0.5289269697959669\n",
      "30 15\n",
      "(43102, 9) (10776, 9) (43102,) (10776,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 43102, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.388842\n",
      "[LightGBM] [Info] Start training from score -2.406704\n",
      "[LightGBM] [Info] Start training from score -2.392643\n",
      "[LightGBM] [Info] Start training from score -2.401568\n",
      "[LightGBM] [Info] Start training from score -2.399521\n",
      "[LightGBM] [Info] Start training from score -2.412384\n",
      "[LightGBM] [Info] Start training from score -2.398243\n",
      "[LightGBM] [Info] Start training from score -2.404903\n",
      "[LightGBM] [Info] Start training from score -2.382036\n",
      "[LightGBM] [Info] Start training from score -2.389854\n",
      "[LightGBM] [Info] Start training from score -2.400544\n",
      "LGBM  0.8035449146250928\n",
      "KN 0.7925946547884187\n",
      "DTC 0.7778396436525612\n",
      "RFC 0.821826280623608\n",
      "0.5290471064256282\n",
      "30 9\n",
      "(71834, 9) (17959, 9) (71834,) (17959,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 71834, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.387440\n",
      "[LightGBM] [Info] Start training from score -2.395046\n",
      "[LightGBM] [Info] Start training from score -2.396268\n",
      "[LightGBM] [Info] Start training from score -2.399944\n",
      "[LightGBM] [Info] Start training from score -2.396421\n",
      "[LightGBM] [Info] Start training from score -2.399330\n",
      "[LightGBM] [Info] Start training from score -2.401172\n",
      "[LightGBM] [Info] Start training from score -2.408574\n",
      "[LightGBM] [Info] Start training from score -2.395657\n",
      "[LightGBM] [Info] Start training from score -2.396727\n",
      "[LightGBM] [Info] Start training from score -2.400404\n",
      "LGBM  0.8076730330196559\n",
      "KN 0.8038866306587227\n",
      "DTC 0.8016036527646305\n",
      "RFC 0.8459825157302745\n",
      "0.5288496876148475\n",
      "60 30\n",
      "(21551, 9) (5388, 9) (21551,) (5388,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 21551, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.400544\n",
      "[LightGBM] [Info] Start training from score -2.391374\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.405160\n",
      "[LightGBM] [Info] Start training from score -2.389854\n",
      "[LightGBM] [Info] Start training from score -2.392896\n",
      "[LightGBM] [Info] Start training from score -2.395439\n",
      "[LightGBM] [Info] Start training from score -2.410315\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.397478\n",
      "LGBM  0.8023385300668151\n",
      "KN 0.7873051224944321\n",
      "DTC 0.7711581291759465\n",
      "RFC 0.8227542687453601\n",
      "0.5292327109395301\n",
      "60 19\n",
      "(34029, 9) (8508, 9) (34029,) (8508,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 34029, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.398395\n",
      "[LightGBM] [Info] Start training from score -2.393555\n",
      "[LightGBM] [Info] Start training from score -2.390021\n",
      "[LightGBM] [Info] Start training from score -2.388099\n",
      "[LightGBM] [Info] Start training from score -2.401310\n",
      "[LightGBM] [Info] Start training from score -2.395811\n",
      "[LightGBM] [Info] Start training from score -2.397102\n",
      "[LightGBM] [Info] Start training from score -2.403258\n",
      "[LightGBM] [Info] Start training from score -2.398718\n",
      "[LightGBM] [Info] Start training from score -2.403908\n",
      "[LightGBM] [Info] Start training from score -2.406839\n",
      "LGBM  0.8249882463563705\n",
      "KN 0.8137047484720263\n",
      "DTC 0.8195815702867889\n",
      "RFC 0.8624823695345557\n",
      "0.5290923196276183\n"
     ]
    }
   ],
   "source": [
    "Window_size = [10,20,30,60]\n",
    "stride = [0.5, 0.333333333]\n",
    "\n",
    "for w in Window_size:\n",
    "    for s in stride:\n",
    "        STRIDE = int(w * s)\n",
    "        print(w, STRIDE)\n",
    "        for i in range(1,12):\n",
    "            data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "            for j in range(0,73462,STRIDE):\n",
    "                temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+w]\n",
    "                MEAN = np.round(np.mean(temp), 3)\n",
    "                MIN = np.min(temp)\n",
    "                MAX = np.max(temp)\n",
    "                STD = np.std(temp)\n",
    "                median = temp.median()\n",
    "                skew = temp.skew()\n",
    "                kurt = temp.kurt()\n",
    "                a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "                data['Group'].append(i)\n",
    "                data['MEAN_TEMP'].append(MEAN)\n",
    "                data['MIN'].append(MIN)\n",
    "                data['MAX'].append(MAX)\n",
    "                data['STD'].append(STD)\n",
    "                data['SKEW'].append(skew)\n",
    "                data['KURT'].append(kurt)\n",
    "                data['MEDIAN'].append(np.round(median,3))\n",
    "                data['25%'].append(np.round(a,3))\n",
    "                data['75%'].append(np.round(b,3))\n",
    "\n",
    "            globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "        TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "        tmp.drop(columns = ['index'], inplace = True)\n",
    "        df_9_cols = tmp\n",
    "        df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "        df_9_cols\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from lightgbm import LGBMClassifier\n",
    "\n",
    "        X = df_9_cols.iloc[:, :9].values\n",
    "        y = df_9_cols['Group'].values\n",
    "\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "        print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "        lgbm.fit(X_train, y_train,\n",
    "                eval_metric = 'multi_logloss',\n",
    "                eval_set = [(X_test, y_test)])\n",
    "        lgbm_predict = lgbm.predict(X_test)\n",
    "        print(\"LGBM \", accuracy_score(y_test, lgbm_predict))\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        print(\"KN\", accuracy_score(y_test, knn_pred))\n",
    "\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        dtc = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "        dtc.fit(X_train, y_train)\n",
    "        dtc_pred = dtc.predict(X_test)\n",
    "        print(\"DTC\", accuracy_score(y_test, dtc_pred))\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        clf_predict = clf.predict(X_test)\n",
    "        print(\"RFC\", accuracy_score(clf_predict, y_test))\n",
    "\n",
    "        X = df_9_cols['MEAN_TEMP'].values\n",
    "        Y = df_9_cols['Group'].values\n",
    "\n",
    "        predict = list(map(THRESHOLD, X))\n",
    "        print(accuracy_score(predict, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMP</th>\n",
       "      <th>STD</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURT</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>label</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284.174</td>\n",
       "      <td>1.466831</td>\n",
       "      <td>281.401</td>\n",
       "      <td>287.082</td>\n",
       "      <td>0.273302</td>\n",
       "      <td>-0.938145</td>\n",
       "      <td>283.754</td>\n",
       "      <td>283.221</td>\n",
       "      <td>285.415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283.417</td>\n",
       "      <td>0.832332</td>\n",
       "      <td>281.401</td>\n",
       "      <td>285.439</td>\n",
       "      <td>0.167324</td>\n",
       "      <td>0.698825</td>\n",
       "      <td>283.408</td>\n",
       "      <td>283.046</td>\n",
       "      <td>283.803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284.153</td>\n",
       "      <td>1.006652</td>\n",
       "      <td>282.463</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>-0.240354</td>\n",
       "      <td>283.809</td>\n",
       "      <td>283.442</td>\n",
       "      <td>284.841</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284.210</td>\n",
       "      <td>1.050080</td>\n",
       "      <td>282.354</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.380891</td>\n",
       "      <td>-0.499881</td>\n",
       "      <td>283.951</td>\n",
       "      <td>283.455</td>\n",
       "      <td>284.948</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284.175</td>\n",
       "      <td>1.081684</td>\n",
       "      <td>282.258</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.305962</td>\n",
       "      <td>-0.501457</td>\n",
       "      <td>283.938</td>\n",
       "      <td>283.430</td>\n",
       "      <td>284.929</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40398</th>\n",
       "      <td>859.455</td>\n",
       "      <td>0.489273</td>\n",
       "      <td>858.268</td>\n",
       "      <td>860.717</td>\n",
       "      <td>0.460233</td>\n",
       "      <td>1.379858</td>\n",
       "      <td>859.475</td>\n",
       "      <td>859.230</td>\n",
       "      <td>859.580</td>\n",
       "      <td>11</td>\n",
       "      <td>40408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40399</th>\n",
       "      <td>859.425</td>\n",
       "      <td>0.547108</td>\n",
       "      <td>858.268</td>\n",
       "      <td>860.717</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.792776</td>\n",
       "      <td>859.469</td>\n",
       "      <td>859.252</td>\n",
       "      <td>859.604</td>\n",
       "      <td>11</td>\n",
       "      <td>40409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40400</th>\n",
       "      <td>859.214</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.769</td>\n",
       "      <td>-0.749589</td>\n",
       "      <td>-0.249938</td>\n",
       "      <td>859.315</td>\n",
       "      <td>858.989</td>\n",
       "      <td>859.472</td>\n",
       "      <td>11</td>\n",
       "      <td>40410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40401</th>\n",
       "      <td>859.047</td>\n",
       "      <td>0.356008</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.755</td>\n",
       "      <td>-0.232467</td>\n",
       "      <td>-0.636235</td>\n",
       "      <td>859.052</td>\n",
       "      <td>858.827</td>\n",
       "      <td>859.327</td>\n",
       "      <td>11</td>\n",
       "      <td>40411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40402</th>\n",
       "      <td>859.031</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>858.522</td>\n",
       "      <td>859.522</td>\n",
       "      <td>0.189010</td>\n",
       "      <td>-0.576731</td>\n",
       "      <td>858.994</td>\n",
       "      <td>858.866</td>\n",
       "      <td>859.242</td>\n",
       "      <td>11</td>\n",
       "      <td>40412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40403 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       "0        284.174  1.466831  281.401  287.082  0.273302 -0.938145  283.754   \n",
       "1        283.417  0.832332  281.401  285.439  0.167324  0.698825  283.408   \n",
       "2        284.153  1.006652  282.463  286.597  0.787491 -0.240354  283.809   \n",
       "3        284.210  1.050080  282.354  286.597  0.380891 -0.499881  283.951   \n",
       "4        284.175  1.081684  282.258  286.597  0.305962 -0.501457  283.938   \n",
       "...          ...       ...      ...      ...       ...       ...      ...   \n",
       "40398    859.455  0.489273  858.268  860.717  0.460233  1.379858  859.475   \n",
       "40399    859.425  0.547108  858.268  860.717  0.029020  0.792776  859.469   \n",
       "40400    859.214  0.371047  858.337  859.769 -0.749589 -0.249938  859.315   \n",
       "40401    859.047  0.356008  858.337  859.755 -0.232467 -0.636235  859.052   \n",
       "40402    859.031  0.264452  858.522  859.522  0.189010 -0.576731  858.994   \n",
       "\n",
       "           25%      75%  label   TIME  \n",
       "0      283.221  285.415      1      0  \n",
       "1      283.046  283.803      1      1  \n",
       "2      283.442  284.841      1      2  \n",
       "3      283.455  284.948      1      3  \n",
       "4      283.430  284.929      1      4  \n",
       "...        ...      ...    ...    ...  \n",
       "40398  859.230  859.580     11  40408  \n",
       "40399  859.252  859.604     11  40409  \n",
       "40400  858.989  859.472     11  40410  \n",
       "40401  858.827  859.327     11  40411  \n",
       "40402  858.866  859.242     11  40412  \n",
       "\n",
       "[40403 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'label' : []}\n",
    "\n",
    "    for j in range(0,73462,20):\n",
    "        temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+60]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['label'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df_9_cols = tmp\n",
    "df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "df_9_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def THRESHOLD(data):\n",
    "    if data>=797.314:\n",
    "        return 11\n",
    "    elif data>=740.9375:\n",
    "        return 10\n",
    "    elif data>=684.5565:\n",
    "        return 9\n",
    "    elif data>=628.1795:\n",
    "        return 8\n",
    "    elif data>=571.7965:\n",
    "        return 7\n",
    "    elif data>=515.4215:\n",
    "        return 6\n",
    "    elif data>=459.045:\n",
    "        return 5\n",
    "    elif data>=402.6645:\n",
    "        return 4\n",
    "    elif data>=346.28:\n",
    "        return 3\n",
    "    elif data>=289/9025:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5289953716308194\n"
     ]
    }
   ],
   "source": [
    "X = df_9_cols['MEAN_TEMP'].values\n",
    "Y = df_9_cols['label'].values\n",
    "\n",
    "predict = list(map(THRESHOLD, X))\n",
    "print(accuracy_score(predict, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "X = df_9_cols.iloc[:, :9].values\n",
    "y = df_9_cols['Group'].values\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2 )\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_metric = 'multi_logloss',\n",
    "         eval_set = [(X_test, y_test)])\n",
    "lgbm_predict = lgbm.predict(X_test)\n",
    "print(\"LGBM \", accuracy_score(y_test, lgbm_predict))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(\"KN\", accuracy_score(y_test, knn_pred))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "print(\"DTC\", accuracy_score(y_test, dtc_pred))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf_predict = clf.predict(X_test)\n",
    "print(\"RFC\", accuracy_score(clf_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def ML(X_train, X_test, y_train, y_test):\n",
    "        KN = []\n",
    "        LGBM = []\n",
    "        DTC = []\n",
    "        RFC = []\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        kn_ac = accuracy_score(y_test, knn_pred)\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators = 100)\n",
    "        lgbm.fit(X_train, y_train,\n",
    "                eval_metric = 'multi_logloss',\n",
    "                eval_set = [(X_test, y_test)])\n",
    "        lgbm_predict = lgbm.predict(X_test)\n",
    "        lgbm_ac = accuracy_score(y_test, lgbm_predict)\n",
    "\n",
    "        dtc = DecisionTreeClassifier()\n",
    "        dtc.fit(X_train, y_train)\n",
    "        dtc_pred = dtc.predict(X_test)\n",
    "        dtc_ac = accuracy_score(y_test, dtc_pred)\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth = 50)\n",
    "        clf.fit(X_train, y_train)\n",
    "        clf_predict = clf.predict(X_test)\n",
    "        clf_ac = accuracy_score(y_test, clf_predict)\n",
    "\n",
    "\n",
    "        return kn_ac, lgbm_ac, dtc_ac, clf_ac\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32322, 9) (8081, 9) (32322,) (8081,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "X = df_9_cols.iloc[:, :9].values\n",
    "y = df_9_cols['label'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2 )\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "2 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "3 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "4 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "5 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "6 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "7 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "8 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "9 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "10 Epochs...\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32322, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.402796\n",
      "[LightGBM] [Info] Start training from score -2.379472\n",
      "[LightGBM] [Info] Start training from score -2.394621\n",
      "[LightGBM] [Info] Start training from score -2.402454\n",
      "[LightGBM] [Info] Start training from score -2.405878\n",
      "[LightGBM] [Info] Start training from score -2.383154\n",
      "[LightGBM] [Info] Start training from score -2.377469\n",
      "[LightGBM] [Info] Start training from score -2.415877\n",
      "[LightGBM] [Info] Start training from score -2.410003\n",
      "[LightGBM] [Info] Start training from score -2.413800\n",
      "[LightGBM] [Info] Start training from score -2.392249\n",
      "KN :  [0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585, 0.8111619849028585]\n",
      "LGBM :  [0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353, 0.8209380027224353]\n",
      "DTC :  [0.8091820319267418, 0.8094295260487563, 0.8096770201707709, 0.8064595965845811, 0.8116569731468878, 0.8078208142556614, 0.8058408612795446, 0.8085632966217052, 0.8085632966217052, 0.809305778987749]\n",
      "RFC :  [0.8542259621333993, 0.8531122385843336, 0.8549684444994431, 0.8545972033164212, 0.8560821680485089, 0.8543497091944067, 0.8523697562182898, 0.8536072268283629, 0.8559584209875015, 0.8542259621333993]\n"
     ]
    }
   ],
   "source": [
    "KN = []\n",
    "LGBM = []\n",
    "DTC = []\n",
    "RFC = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"{epoch+1} Epochs...\")\n",
    "    print()\n",
    "    \n",
    "    kn_ac, lgbm_ac, dtc_ac, clf_ac = ML(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    KN.append(kn_ac)\n",
    "    LGBM.append(lgbm_ac)\n",
    "    DTC.append(dtc_ac)\n",
    "    RFC.append(clf_ac)\n",
    "\n",
    "print(\"KN : \", KN)\n",
    "print(\"LGBM : \", LGBM)\n",
    "print(\"DTC : \", DTC)\n",
    "print(\"RFC : \", RFC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8111619849028585,\n",
       " 0.8209380027224353,\n",
       " 0.8086499195644103,\n",
       " 0.8543497091944067)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(KN), np.mean(LGBM), np.mean(DTC ), np.mean(RFC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(KN) - np.max(KN), np.mean(KN) - np.min(KN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(LGBM) - np.max(LGBM), np.mean(LGBM) - np.min(LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.003007053582477437, 0.002809058284865773)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(DTC) - np.max(DTC), np.mean(DTC) - np.min(DTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0017324588541022257, 0.001979952976116861)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(RFC) - np.max(RFC), np.mean(RFC) - np.min(RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [10,20,30,60,80,120,240]\n",
    "y_axis = [82.47, 84.342, 85.771, 87.385, 87.302, 86.387, 85.965]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\seaborn\\_oldcore.py:1765: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  order = pd.unique(vector)\n",
      "c:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (15,8))\n",
    "g = sns.pointplot(x = x_axis, y = y_axis)\n",
    "plt.xlabel('Window size')\n",
    "plt.ylabel('Random Forest Accuracy')\n",
    "g.set_xticklabels(['10','20','30','60','80','120','240'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_1_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\machine_learning.ipynb 셀 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/machine_learning.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m STRIDE \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(w\u001b[39m*\u001b[39mstride)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/machine_learning.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m12\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/machine_learning.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     func_dataframe \u001b[39m=\u001b[39m \u001b[39mglobals\u001b[39;49m()[\u001b[39m'\u001b[39;49m\u001b[39mdf_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(i)\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_temp\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/machine_learning.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mglobals\u001b[39m()[\u001b[39m'\u001b[39m\u001b[39mgroup_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)] \u001b[39m=\u001b[39m make_group_data(func_dataframe, w, STRIDE, i)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'df_1_temp'"
     ]
    }
   ],
   "source": [
    "from data_group import make_group_data\n",
    "\n",
    "Window_size = [10,20,30,60,80,120,240]\n",
    "stride = 0.333333333\n",
    "\n",
    "for w in Window_size:\n",
    "    STRIDE = int(w*stride)\n",
    "\n",
    "    for i in range(1,12):\n",
    "        func_dataframe = globals()['df_'+str(i)+'_temp']\n",
    "        globals()['group_'+str(i)] = make_group_data(func_dataframe, w, STRIDE, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_group import make_group_data\n",
    "Window_size = [10,20,30,60,80,120,240]\n",
    "stride = 0.333333333\n",
    "\n",
    "for w in Window_size:\n",
    "    for s in stride:\n",
    "        STRIDE = int(w * s)\n",
    "        print(w, STRIDE)\n",
    "        func_dataframe = globals()['df_'+str(i)+'_temp']\n",
    "        for i in range(1,12):\n",
    "            data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "            for j in range(0,73462,STRIDE):\n",
    "                temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+w]\n",
    "                MEAN = np.round(np.mean(temp), 3)\n",
    "                MIN = np.min(temp)\n",
    "                MAX = np.max(temp)\n",
    "                STD = np.std(temp)\n",
    "                median = temp.median()\n",
    "                skew = temp.skew()\n",
    "                kurt = temp.kurt()\n",
    "                a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "                data['Group'].append(i)\n",
    "                data['MEAN_TEMP'].append(MEAN)\n",
    "                data['MIN'].append(MIN)\n",
    "                data['MAX'].append(MAX)\n",
    "                data['STD'].append(STD)\n",
    "                data['SKEW'].append(skew)\n",
    "                data['KURT'].append(kurt)\n",
    "                data['MEDIAN'].append(np.round(median,3))\n",
    "                data['25%'].append(np.round(a,3))\n",
    "                data['75%'].append(np.round(b,3))\n",
    "\n",
    "            globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "        TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "        tmp.drop(columns = ['index'], inplace = True)\n",
    "        df_9_cols = tmp\n",
    "        df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "        df_9_cols\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from lightgbm import LGBMClassifier\n",
    "\n",
    "        X = df_9_cols.iloc[:, :9].values\n",
    "        y = df_9_cols['Group'].values\n",
    "\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "        print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "        lgbm.fit(X_train, y_train,\n",
    "                eval_metric = 'multi_logloss',\n",
    "                eval_set = [(X_test, y_test)])\n",
    "        lgbm_predict = lgbm.predict(X_test)\n",
    "        print(\"LGBM \", accuracy_score(y_test, lgbm_predict))\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        print(\"KN\", accuracy_score(y_test, knn_pred))\n",
    "\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        dtc = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "        dtc.fit(X_train, y_train)\n",
    "        dtc_pred = dtc.predict(X_test)\n",
    "        print(\"DTC\", accuracy_score(y_test, dtc_pred))\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        clf_predict = clf.predict(X_test)\n",
    "        print(\"RFC\", accuracy_score(clf_predict, y_test))\n",
    "\n",
    "        X = df_9_cols['MEAN_TEMP'].values\n",
    "        Y = df_9_cols['Group'].values\n",
    "\n",
    "        predict = list(map(THRESHOLD, X))\n",
    "        print(accuracy_score(predict, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cho():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
