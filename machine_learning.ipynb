{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7347\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMP</th>\n",
       "      <th>STD</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURT</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Group</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285.886</td>\n",
       "      <td>0.703473</td>\n",
       "      <td>284.483</td>\n",
       "      <td>287.082</td>\n",
       "      <td>-0.295420</td>\n",
       "      <td>-0.875405</td>\n",
       "      <td>285.893</td>\n",
       "      <td>285.274</td>\n",
       "      <td>286.394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284.200</td>\n",
       "      <td>1.858006</td>\n",
       "      <td>281.401</td>\n",
       "      <td>286.690</td>\n",
       "      <td>-0.067890</td>\n",
       "      <td>-1.659449</td>\n",
       "      <td>284.126</td>\n",
       "      <td>282.486</td>\n",
       "      <td>285.963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282.799</td>\n",
       "      <td>0.721184</td>\n",
       "      <td>281.401</td>\n",
       "      <td>284.014</td>\n",
       "      <td>-0.285944</td>\n",
       "      <td>-0.801952</td>\n",
       "      <td>282.885</td>\n",
       "      <td>282.242</td>\n",
       "      <td>283.295</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283.295</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>282.306</td>\n",
       "      <td>284.014</td>\n",
       "      <td>-0.567776</td>\n",
       "      <td>-0.220987</td>\n",
       "      <td>283.327</td>\n",
       "      <td>283.082</td>\n",
       "      <td>283.642</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283.836</td>\n",
       "      <td>0.709563</td>\n",
       "      <td>283.085</td>\n",
       "      <td>285.439</td>\n",
       "      <td>1.343684</td>\n",
       "      <td>0.750411</td>\n",
       "      <td>283.647</td>\n",
       "      <td>283.312</td>\n",
       "      <td>283.884</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80801</th>\n",
       "      <td>859.483</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>859.055</td>\n",
       "      <td>859.769</td>\n",
       "      <td>-0.407907</td>\n",
       "      <td>-0.315194</td>\n",
       "      <td>859.477</td>\n",
       "      <td>859.378</td>\n",
       "      <td>859.658</td>\n",
       "      <td>11</td>\n",
       "      <td>80811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80802</th>\n",
       "      <td>859.064</td>\n",
       "      <td>0.434339</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.755</td>\n",
       "      <td>-0.409836</td>\n",
       "      <td>-1.079603</td>\n",
       "      <td>859.194</td>\n",
       "      <td>858.643</td>\n",
       "      <td>859.396</td>\n",
       "      <td>11</td>\n",
       "      <td>80812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80803</th>\n",
       "      <td>858.936</td>\n",
       "      <td>0.407331</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.522</td>\n",
       "      <td>-0.032319</td>\n",
       "      <td>-1.664372</td>\n",
       "      <td>858.917</td>\n",
       "      <td>858.602</td>\n",
       "      <td>859.322</td>\n",
       "      <td>11</td>\n",
       "      <td>80813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80804</th>\n",
       "      <td>859.058</td>\n",
       "      <td>0.262727</td>\n",
       "      <td>858.522</td>\n",
       "      <td>859.522</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>-0.418698</td>\n",
       "      <td>858.999</td>\n",
       "      <td>858.941</td>\n",
       "      <td>859.286</td>\n",
       "      <td>11</td>\n",
       "      <td>80814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80805</th>\n",
       "      <td>858.956</td>\n",
       "      <td>0.110925</td>\n",
       "      <td>858.717</td>\n",
       "      <td>859.141</td>\n",
       "      <td>-0.658286</td>\n",
       "      <td>0.438145</td>\n",
       "      <td>858.988</td>\n",
       "      <td>858.894</td>\n",
       "      <td>859.013</td>\n",
       "      <td>11</td>\n",
       "      <td>80815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80806 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       "0        285.886  0.703473  284.483  287.082 -0.295420 -0.875405  285.893   \n",
       "1        284.200  1.858006  281.401  286.690 -0.067890 -1.659449  284.126   \n",
       "2        282.799  0.721184  281.401  284.014 -0.285944 -0.801952  282.885   \n",
       "3        283.295  0.440360  282.306  284.014 -0.567776 -0.220987  283.327   \n",
       "4        283.836  0.709563  283.085  285.439  1.343684  0.750411  283.647   \n",
       "...          ...       ...      ...      ...       ...       ...      ...   \n",
       "80801    859.483  0.195625  859.055  859.769 -0.407907 -0.315194  859.477   \n",
       "80802    859.064  0.434339  858.337  859.755 -0.409836 -1.079603  859.194   \n",
       "80803    858.936  0.407331  858.337  859.522 -0.032319 -1.664372  858.917   \n",
       "80804    859.058  0.262727  858.522  859.522  0.008027 -0.418698  858.999   \n",
       "80805    858.956  0.110925  858.717  859.141 -0.658286  0.438145  858.988   \n",
       "\n",
       "           25%      75%  Group   TIME  \n",
       "0      285.274  286.394      1      0  \n",
       "1      282.486  285.963      1      1  \n",
       "2      282.242  283.295      1      2  \n",
       "3      283.082  283.642      1      3  \n",
       "4      283.312  283.884      1      4  \n",
       "...        ...      ...    ...    ...  \n",
       "80801  859.378  859.658     11  80811  \n",
       "80802  858.643  859.396     11  80812  \n",
       "80803  858.602  859.322     11  80813  \n",
       "80804  858.941  859.286     11  80814  \n",
       "80805  858.894  859.013     11  80815  \n",
       "\n",
       "[80806 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./new_temp_file/temperature_time')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_temp'] = df[73462*(i-1):73462*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_temp']['TEMP'].mean()\n",
    "    diff  = 283.733148 - mean\n",
    "    globals()['df_'+str(i)+'_temp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_temp'] = globals()['df_'+str(i-5)+'_temp'].copy()\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_temp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_temp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(73462)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_temp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_temp']['TEMP'] = series\n",
    "\n",
    "df_temp_all = pd.concat([df_1_temp, df_2_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_3_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_4_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_5_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_6_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_7_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_8_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_9_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_10_temp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_11_temp], axis = 0)\n",
    "df_temp_all = df_temp_all.reset_index().drop(columns=['index','TIME'])\n",
    "tmp = np.arange(808082)\n",
    "TIME = pd.DataFrame({'TIME' : tmp})\n",
    "df_temp_all = pd.concat([df_temp_all, TIME], axis = 1)\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(0,73462,15):\n",
    "        temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+20]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df_9_cols = tmp\n",
    "df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "df_9_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Window_size = [10,20,30,60]\n",
    "stride = [0.5, 1/3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5\n",
      "10 3\n",
      "20 10\n",
      "20 6\n",
      "30 15\n",
      "30 10\n",
      "60 30\n",
      "60 20\n"
     ]
    }
   ],
   "source": [
    "for w in Window_size:\n",
    "    for s in stride:\n",
    "        STRIDE = int(w * s)\n",
    "        print(w, STRIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def THRESHOLD(data):\n",
    "    if data>=797.314:\n",
    "        return 11\n",
    "    elif data>=740.9375:\n",
    "        return 10\n",
    "    elif data>=684.5565:\n",
    "        return 9\n",
    "    elif data>=628.1795:\n",
    "        return 8\n",
    "    elif data>=571.7965:\n",
    "        return 7\n",
    "    elif data>=515.4215:\n",
    "        return 6\n",
    "    elif data>=459.045:\n",
    "        return 5\n",
    "    elif data>=402.6645:\n",
    "        return 4\n",
    "    elif data>=346.28:\n",
    "        return 3\n",
    "    elif data>=289/9025:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5\n",
      "(129289, 9) (32323, 9) (129289,) (32323,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 129289, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.395817\n",
      "[LightGBM] [Info] Start training from score -2.400412\n",
      "[LightGBM] [Info] Start training from score -2.395732\n",
      "[LightGBM] [Info] Start training from score -2.393188\n",
      "[LightGBM] [Info] Start training from score -2.397686\n",
      "[LightGBM] [Info] Start training from score -2.401692\n",
      "[LightGBM] [Info] Start training from score -2.395987\n",
      "[LightGBM] [Info] Start training from score -2.394374\n",
      "[LightGBM] [Info] Start training from score -2.400242\n",
      "[LightGBM] [Info] Start training from score -2.402205\n",
      "[LightGBM] [Info] Start training from score -2.399560\n",
      "LGBM  0.7782074683661789\n",
      "KN 0.7661726943662408\n",
      "DTC 0.731708071651765\n",
      "RFC 0.7929028864894967\n",
      "0.5287540529168626\n",
      "10 3\n",
      "(215485, 9) (53872, 9) (215485,) (53872,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 215485, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.396801\n",
      "[LightGBM] [Info] Start training from score -2.397413\n",
      "[LightGBM] [Info] Start training from score -2.399251\n",
      "[LightGBM] [Info] Start training from score -2.398740\n",
      "[LightGBM] [Info] Start training from score -2.396699\n",
      "[LightGBM] [Info] Start training from score -2.397158\n",
      "[LightGBM] [Info] Start training from score -2.399047\n",
      "[LightGBM] [Info] Start training from score -2.398178\n",
      "[LightGBM] [Info] Start training from score -2.399302\n",
      "[LightGBM] [Info] Start training from score -2.403195\n",
      "[LightGBM] [Info] Start training from score -2.391106\n",
      "LGBM  0.7816676566676567\n",
      "KN 0.7757090882090882\n",
      "DTC 0.7565896940896941\n",
      "RFC 0.8105880605880605\n",
      "0.5286886919589987\n",
      "20 10\n",
      "(64644, 9) (16162, 9) (64644,) (16162,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 64644, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.389040\n",
      "[LightGBM] [Info] Start training from score -2.399893\n",
      "[LightGBM] [Info] Start training from score -2.394960\n",
      "[LightGBM] [Info] Start training from score -2.398870\n",
      "[LightGBM] [Info] Start training from score -2.394452\n",
      "[LightGBM] [Info] Start training from score -2.395639\n",
      "[LightGBM] [Info] Start training from score -2.414492\n",
      "[LightGBM] [Info] Start training from score -2.395470\n",
      "[LightGBM] [Info] Start training from score -2.393096\n",
      "[LightGBM] [Info] Start training from score -2.403138\n",
      "[LightGBM] [Info] Start training from score -2.398019\n",
      "LGBM  0.7921049375077341\n",
      "KN 0.7783071402054201\n",
      "DTC 0.7564657839376315\n",
      "RFC 0.8112238584333622\n",
      "0.5289334950374972\n",
      "20 6\n",
      "(107747, 9) (26937, 9) (107747,) (26937,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 107747, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.392314\n",
      "[LightGBM] [Info] Start training from score -2.401391\n",
      "[LightGBM] [Info] Start training from score -2.401596\n",
      "[LightGBM] [Info] Start training from score -2.392213\n",
      "[LightGBM] [Info] Start training from score -2.401698\n",
      "[LightGBM] [Info] Start training from score -2.395161\n",
      "[LightGBM] [Info] Start training from score -2.395568\n",
      "[LightGBM] [Info] Start training from score -2.400674\n",
      "[LightGBM] [Info] Start training from score -2.396689\n",
      "[LightGBM] [Info] Start training from score -2.401596\n",
      "[LightGBM] [Info] Start training from score -2.398016\n",
      "LGBM  0.8027620002227419\n",
      "KN 0.7978245535880016\n",
      "DTC 0.7860192300553143\n",
      "RFC 0.8391431859524074\n",
      "0.5289269697959669\n",
      "30 15\n",
      "(43102, 9) (10776, 9) (43102,) (10776,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 43102, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.388842\n",
      "[LightGBM] [Info] Start training from score -2.406704\n",
      "[LightGBM] [Info] Start training from score -2.392643\n",
      "[LightGBM] [Info] Start training from score -2.401568\n",
      "[LightGBM] [Info] Start training from score -2.399521\n",
      "[LightGBM] [Info] Start training from score -2.412384\n",
      "[LightGBM] [Info] Start training from score -2.398243\n",
      "[LightGBM] [Info] Start training from score -2.404903\n",
      "[LightGBM] [Info] Start training from score -2.382036\n",
      "[LightGBM] [Info] Start training from score -2.389854\n",
      "[LightGBM] [Info] Start training from score -2.400544\n",
      "LGBM  0.8035449146250928\n",
      "KN 0.7925946547884187\n",
      "DTC 0.7778396436525612\n",
      "RFC 0.821826280623608\n",
      "0.5290471064256282\n",
      "30 9\n",
      "(71834, 9) (17959, 9) (71834,) (17959,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 71834, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.387440\n",
      "[LightGBM] [Info] Start training from score -2.395046\n",
      "[LightGBM] [Info] Start training from score -2.396268\n",
      "[LightGBM] [Info] Start training from score -2.399944\n",
      "[LightGBM] [Info] Start training from score -2.396421\n",
      "[LightGBM] [Info] Start training from score -2.399330\n",
      "[LightGBM] [Info] Start training from score -2.401172\n",
      "[LightGBM] [Info] Start training from score -2.408574\n",
      "[LightGBM] [Info] Start training from score -2.395657\n",
      "[LightGBM] [Info] Start training from score -2.396727\n",
      "[LightGBM] [Info] Start training from score -2.400404\n",
      "LGBM  0.8076730330196559\n",
      "KN 0.8038866306587227\n",
      "DTC 0.8016036527646305\n",
      "RFC 0.8459825157302745\n",
      "0.5288496876148475\n",
      "60 30\n",
      "(21551, 9) (5388, 9) (21551,) (5388,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 21551, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.400544\n",
      "[LightGBM] [Info] Start training from score -2.391374\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.405160\n",
      "[LightGBM] [Info] Start training from score -2.389854\n",
      "[LightGBM] [Info] Start training from score -2.392896\n",
      "[LightGBM] [Info] Start training from score -2.395439\n",
      "[LightGBM] [Info] Start training from score -2.410315\n",
      "[LightGBM] [Info] Start training from score -2.397988\n",
      "[LightGBM] [Info] Start training from score -2.397478\n",
      "LGBM  0.8023385300668151\n",
      "KN 0.7873051224944321\n",
      "DTC 0.7711581291759465\n",
      "RFC 0.8227542687453601\n",
      "0.5292327109395301\n",
      "60 19\n",
      "(34029, 9) (8508, 9) (34029,) (8508,)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 34029, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.398395\n",
      "[LightGBM] [Info] Start training from score -2.393555\n",
      "[LightGBM] [Info] Start training from score -2.390021\n",
      "[LightGBM] [Info] Start training from score -2.388099\n",
      "[LightGBM] [Info] Start training from score -2.401310\n",
      "[LightGBM] [Info] Start training from score -2.395811\n",
      "[LightGBM] [Info] Start training from score -2.397102\n",
      "[LightGBM] [Info] Start training from score -2.403258\n",
      "[LightGBM] [Info] Start training from score -2.398718\n",
      "[LightGBM] [Info] Start training from score -2.403908\n",
      "[LightGBM] [Info] Start training from score -2.406839\n",
      "LGBM  0.8249882463563705\n",
      "KN 0.8137047484720263\n",
      "DTC 0.8195815702867889\n",
      "RFC 0.8624823695345557\n",
      "0.5290923196276183\n"
     ]
    }
   ],
   "source": [
    "Window_size = [10,20,30,60]\n",
    "stride = [0.5, 0.333333333]\n",
    "\n",
    "for w in Window_size:\n",
    "    for s in stride:\n",
    "        STRIDE = int(w * s)\n",
    "        print(w, STRIDE)\n",
    "        for i in range(1,12):\n",
    "            data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "            for j in range(0,73462,STRIDE):\n",
    "                temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+w]\n",
    "                MEAN = np.round(np.mean(temp), 3)\n",
    "                MIN = np.min(temp)\n",
    "                MAX = np.max(temp)\n",
    "                STD = np.std(temp)\n",
    "                median = temp.median()\n",
    "                skew = temp.skew()\n",
    "                kurt = temp.kurt()\n",
    "                a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "                data['Group'].append(i)\n",
    "                data['MEAN_TEMP'].append(MEAN)\n",
    "                data['MIN'].append(MIN)\n",
    "                data['MAX'].append(MAX)\n",
    "                data['STD'].append(STD)\n",
    "                data['SKEW'].append(skew)\n",
    "                data['KURT'].append(kurt)\n",
    "                data['MEDIAN'].append(np.round(median,3))\n",
    "                data['25%'].append(np.round(a,3))\n",
    "                data['75%'].append(np.round(b,3))\n",
    "\n",
    "            globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "        tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "        TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "        tmp.drop(columns = ['index'], inplace = True)\n",
    "        df_9_cols = tmp\n",
    "        df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "        df_9_cols\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from lightgbm import LGBMClassifier\n",
    "\n",
    "        X = df_9_cols.iloc[:, :9].values\n",
    "        y = df_9_cols['Group'].values\n",
    "\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "        print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "        lgbm.fit(X_train, y_train,\n",
    "                eval_metric = 'multi_logloss',\n",
    "                eval_set = [(X_test, y_test)])\n",
    "        lgbm_predict = lgbm.predict(X_test)\n",
    "        print(\"LGBM \", accuracy_score(y_test, lgbm_predict))\n",
    "\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        print(\"KN\", accuracy_score(y_test, knn_pred))\n",
    "\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        dtc = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "        dtc.fit(X_train, y_train)\n",
    "        dtc_pred = dtc.predict(X_test)\n",
    "        print(\"DTC\", accuracy_score(y_test, dtc_pred))\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        clf_predict = clf.predict(X_test)\n",
    "        print(\"RFC\", accuracy_score(clf_predict, y_test))\n",
    "\n",
    "        X = df_9_cols['MEAN_TEMP'].values\n",
    "        Y = df_9_cols['Group'].values\n",
    "\n",
    "        predict = list(map(THRESHOLD, X))\n",
    "        print(accuracy_score(predict, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMP</th>\n",
       "      <th>STD</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURT</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Group</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284.174</td>\n",
       "      <td>1.466831</td>\n",
       "      <td>281.401</td>\n",
       "      <td>287.082</td>\n",
       "      <td>0.273302</td>\n",
       "      <td>-0.938145</td>\n",
       "      <td>283.754</td>\n",
       "      <td>283.221</td>\n",
       "      <td>285.415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283.417</td>\n",
       "      <td>0.832332</td>\n",
       "      <td>281.401</td>\n",
       "      <td>285.439</td>\n",
       "      <td>0.167324</td>\n",
       "      <td>0.698825</td>\n",
       "      <td>283.408</td>\n",
       "      <td>283.046</td>\n",
       "      <td>283.803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284.153</td>\n",
       "      <td>1.006652</td>\n",
       "      <td>282.463</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>-0.240354</td>\n",
       "      <td>283.809</td>\n",
       "      <td>283.442</td>\n",
       "      <td>284.841</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284.210</td>\n",
       "      <td>1.050080</td>\n",
       "      <td>282.354</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.380891</td>\n",
       "      <td>-0.499881</td>\n",
       "      <td>283.951</td>\n",
       "      <td>283.455</td>\n",
       "      <td>284.948</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284.175</td>\n",
       "      <td>1.081684</td>\n",
       "      <td>282.258</td>\n",
       "      <td>286.597</td>\n",
       "      <td>0.305962</td>\n",
       "      <td>-0.501457</td>\n",
       "      <td>283.938</td>\n",
       "      <td>283.430</td>\n",
       "      <td>284.929</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40398</th>\n",
       "      <td>859.455</td>\n",
       "      <td>0.489273</td>\n",
       "      <td>858.268</td>\n",
       "      <td>860.717</td>\n",
       "      <td>0.460233</td>\n",
       "      <td>1.379858</td>\n",
       "      <td>859.475</td>\n",
       "      <td>859.230</td>\n",
       "      <td>859.580</td>\n",
       "      <td>11</td>\n",
       "      <td>40408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40399</th>\n",
       "      <td>859.425</td>\n",
       "      <td>0.547108</td>\n",
       "      <td>858.268</td>\n",
       "      <td>860.717</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.792776</td>\n",
       "      <td>859.469</td>\n",
       "      <td>859.252</td>\n",
       "      <td>859.604</td>\n",
       "      <td>11</td>\n",
       "      <td>40409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40400</th>\n",
       "      <td>859.214</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.769</td>\n",
       "      <td>-0.749589</td>\n",
       "      <td>-0.249938</td>\n",
       "      <td>859.315</td>\n",
       "      <td>858.989</td>\n",
       "      <td>859.472</td>\n",
       "      <td>11</td>\n",
       "      <td>40410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40401</th>\n",
       "      <td>859.047</td>\n",
       "      <td>0.356008</td>\n",
       "      <td>858.337</td>\n",
       "      <td>859.755</td>\n",
       "      <td>-0.232467</td>\n",
       "      <td>-0.636235</td>\n",
       "      <td>859.052</td>\n",
       "      <td>858.827</td>\n",
       "      <td>859.327</td>\n",
       "      <td>11</td>\n",
       "      <td>40411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40402</th>\n",
       "      <td>859.031</td>\n",
       "      <td>0.264452</td>\n",
       "      <td>858.522</td>\n",
       "      <td>859.522</td>\n",
       "      <td>0.189010</td>\n",
       "      <td>-0.576731</td>\n",
       "      <td>858.994</td>\n",
       "      <td>858.866</td>\n",
       "      <td>859.242</td>\n",
       "      <td>11</td>\n",
       "      <td>40412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40403 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       "0        284.174  1.466831  281.401  287.082  0.273302 -0.938145  283.754   \n",
       "1        283.417  0.832332  281.401  285.439  0.167324  0.698825  283.408   \n",
       "2        284.153  1.006652  282.463  286.597  0.787491 -0.240354  283.809   \n",
       "3        284.210  1.050080  282.354  286.597  0.380891 -0.499881  283.951   \n",
       "4        284.175  1.081684  282.258  286.597  0.305962 -0.501457  283.938   \n",
       "...          ...       ...      ...      ...       ...       ...      ...   \n",
       "40398    859.455  0.489273  858.268  860.717  0.460233  1.379858  859.475   \n",
       "40399    859.425  0.547108  858.268  860.717  0.029020  0.792776  859.469   \n",
       "40400    859.214  0.371047  858.337  859.769 -0.749589 -0.249938  859.315   \n",
       "40401    859.047  0.356008  858.337  859.755 -0.232467 -0.636235  859.052   \n",
       "40402    859.031  0.264452  858.522  859.522  0.189010 -0.576731  858.994   \n",
       "\n",
       "           25%      75%  Group   TIME  \n",
       "0      283.221  285.415      1      0  \n",
       "1      283.046  283.803      1      1  \n",
       "2      283.442  284.841      1      2  \n",
       "3      283.455  284.948      1      3  \n",
       "4      283.430  284.929      1      4  \n",
       "...        ...      ...    ...    ...  \n",
       "40398  859.230  859.580     11  40408  \n",
       "40399  859.252  859.604     11  40409  \n",
       "40400  858.989  859.472     11  40410  \n",
       "40401  858.827  859.327     11  40411  \n",
       "40402  858.866  859.242     11  40412  \n",
       "\n",
       "[40403 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(0,73462,20):\n",
    "        temp = globals()['df_'+str(i)+'_temp']['TEMP'][j:j+60]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(len(tmp))})\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df_9_cols = tmp\n",
    "df_9_cols = df_9_cols.dropna(axis = 0).reset_index().drop(columns=['index'])\n",
    "df_9_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def THRESHOLD(data):\n",
    "    if data>=797.314:\n",
    "        return 11\n",
    "    elif data>=740.9375:\n",
    "        return 10\n",
    "    elif data>=684.5565:\n",
    "        return 9\n",
    "    elif data>=628.1795:\n",
    "        return 8\n",
    "    elif data>=571.7965:\n",
    "        return 7\n",
    "    elif data>=515.4215:\n",
    "        return 6\n",
    "    elif data>=459.045:\n",
    "        return 5\n",
    "    elif data>=402.6645:\n",
    "        return 4\n",
    "    elif data>=346.28:\n",
    "        return 3\n",
    "    elif data>=289/9025:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5289953716308194\n"
     ]
    }
   ],
   "source": [
    "X = df_9_cols['MEAN_TEMP'].values\n",
    "Y = df_9_cols['Group'].values\n",
    "\n",
    "predict = list(map(THRESHOLD, X))\n",
    "print(accuracy_score(predict, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "X = df_9_cols.iloc[:, :9].values\n",
    "y = df_9_cols['Group'].values\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_metric = 'multi_logloss',\n",
    "         eval_set = [(X_test, y_test)])\n",
    "lgbm_predict = lgbm.predict(X_test)\n",
    "print(\"LGBM \", accuracy_score(y_test, lgbm_predict))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(\"KN\", accuracy_score(y_test, knn_pred))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "print(\"DTC\", accuracy_score(y_test, dtc_pred))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf_predict = clf.predict(X_test)\n",
    "print(\"RFC\", accuracy_score(clf_predict, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
