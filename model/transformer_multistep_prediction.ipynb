{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C ����̺��� �������� �̸��� �����ϴ�.\n",
      " ���� �Ϸ� ��ȣ: 702E-35B2\n",
      "\n",
      " c:\\Users\\Sejong\\Desktop\\hanhwa\\model ���͸�\n",
      "\n",
      "2023-11-28  ���� 11:18    <DIR>          .\n",
      "2023-12-11  ���� 10:17    <DIR>          ..\n",
      "2023-11-28  ���� 11:07                 0 __init__.py\n",
      "2023-11-28  ���� 11:43    <DIR>          __pycache__\n",
      "2023-12-05  ���� 09:58               891 LSTM_multi_step.ipynb\n",
      "2023-12-01  ���� 10:38           156,156 LSTM_Single_Step.ipynb\n",
      "2023-12-11  ���� 02:06            24,887 transformer_multistep_prediction.ipynb\n",
      "2023-11-28  ���� 11:43            12,578 transformer_singlestep.py\n",
      "2023-12-03  ���� 06:27           168,260 transformer_singlestep_prediction_11_24.ipynb\n",
      "               6�� ����             362,772 ����Ʈ\n",
      "               3�� ���͸�  244,493,590,528 ����Ʈ ����\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sejong\\Desktop\\hanhwa\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# This concept is also called teacher forceing. \n",
    "# The flag decides if the loss will be calculted over all \n",
    "# or just the predicted values.\n",
    "calculate_loss_over_all_values = False\n",
    "\n",
    "# S is the source sequence length\n",
    "# T is the target sequence length\n",
    "# N is the batch size\n",
    "# E is the feature number\n",
    "\n",
    "#src = torch.rand((10, 32, 512)) # (S,N,E) \n",
    "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
    "#out = transformer_model(src, tgt)\n",
    "#\n",
    "#print(out)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "input_window = 100\n",
    "output_window = 60\n",
    "batch_size = 512 # batch size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments : \n",
    "            x : Tensor, shape : [input_window, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "       \n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+tw]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "from function_file.time_series import time_series_dataframe\n",
    "\n",
    "def get_data():\n",
    "    time        = np.arange(0, 400, 0.1) # 4000 sample\n",
    "    amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    #amplitude = scaler.fit_transform(df.reshape(-1, 1)).reshape(-1)\n",
    "    #from pandas import read_csv\n",
    "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "    df = time_series_dataframe()\n",
    "    df = df['TEMP'].values   \n",
    "    \n",
    "    train_len = int(len(df) * 0.7)\n",
    "    train_data = df[:train_len] \n",
    "    test_data = df[train_len:] \n",
    "    train_data = scaler_train.fit_transform(train_data.reshape(-1,1)).reshape(-1)\n",
    "    test_data = scaler_test.fit_transform(test_data.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment.. \n",
    "    train_sequence = create_inout_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window] #todo: fix hack?\n",
    "\n",
    "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
    "    test_data = create_inout_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window] #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device), test_data.to(device)\n",
    "\n",
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]    \n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def train(train_data):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        data, targets = get_batch(train_data, i,batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)        \n",
    "\n",
    "        if calculate_loss_over_all_values:\n",
    "            loss = criterion(output, targets)\n",
    "        else:\n",
    "            loss = criterion(output[-output_window:], targets[-output_window:])\n",
    "    \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_data) / batch_size / 5)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def plot_and_loss(eval_model, data_source):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            # look like the model returns static values for the output window\n",
    "            output = eval_model(data)\n",
    "            if calculate_loss_over_all_values:                                \n",
    "                total_loss += criterion(output, target).item()\n",
    "            else:\n",
    "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
    "            \n",
    "            test_result = torch.cat((test_result, output[-output_window:].view(-1).cpu()), 0) #todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth, target[-output_window:].view(-1).cpu()), 0)\n",
    "            \n",
    "    #test_result = test_result.cpu().numpy()\n",
    "\n",
    "    test_result = scaler_test.inverse_transform(test_result.reshape(-1,1)).reshape(-1)\n",
    "    truth = scaler_test.inverse_transform(truth.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    pyplot.plot(test_result,color=\"red\")\n",
    "    pyplot.plot(truth,color=\"blue\")\n",
    "    #pyplot.plot(test_result-truth,color=\"green\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.show()\n",
    "    pyplot.close()\n",
    "    \n",
    "    return test_result, truth, total_loss / i\n",
    "\n",
    "\n",
    "def predict_future(eval_model, data_source,steps):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    data, _  = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "            \n",
    "    data = data.cpu().view(-1)\n",
    "    \n",
    "    data = scaler_test.inverse_transform(data.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.show()\n",
    "    pyplot.close()\n",
    "        \n",
    "# There is either an error in the loss or in the train method, but the results are different\n",
    "# also to those of the predict_future\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 512\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
    "            output = eval_model(data)            \n",
    "            if calculate_loss_over_all_values:\n",
    "                total_loss += len(data[0])* criterion(output, targets).cpu().item()\n",
    "            else:                                \n",
    "                total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).cpu().item()            \n",
    "    return total_loss / len(data_source)\n",
    "\n",
    "\n",
    "\n",
    "#src = torch.rand(input_window, batch_size, 1) # (source sequence length,batch size,feature number) \n",
    "#out = model(src)\n",
    "#\n",
    "#print(out)\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   283/ 1416 batches | lr 0.001000 | 52.71 ms | loss 0.54110 | ppl     1.72\n",
      "| epoch   1 |   566/ 1416 batches | lr 0.001000 | 52.70 ms | loss 0.01254 | ppl     1.01\n",
      "| epoch   1 |   849/ 1416 batches | lr 0.001000 | 52.45 ms | loss 0.02079 | ppl     1.02\n",
      "| epoch   1 |  1132/ 1416 batches | lr 0.001000 | 53.32 ms | loss 0.00512 | ppl     1.01\n",
      "| epoch   1 |  1415/ 1416 batches | lr 0.001000 | 52.60 ms | loss 0.02328 | ppl     1.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 81.69s | valid loss 0.10070 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   283/ 1416 batches | lr 0.000960 | 53.66 ms | loss 0.00744 | ppl     1.01\n",
      "| epoch   2 |   566/ 1416 batches | lr 0.000960 | 53.79 ms | loss 0.01522 | ppl     1.02\n",
      "| epoch   2 |   849/ 1416 batches | lr 0.000960 | 55.22 ms | loss 0.03559 | ppl     1.04\n",
      "| epoch   2 |  1132/ 1416 batches | lr 0.000960 | 52.90 ms | loss 0.00682 | ppl     1.01\n",
      "| epoch   2 |  1415/ 1416 batches | lr 0.000960 | 52.28 ms | loss 0.03236 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 82.83s | valid loss 0.10060 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   283/ 1416 batches | lr 0.000941 | 53.00 ms | loss 0.00939 | ppl     1.01\n",
      "| epoch   3 |   566/ 1416 batches | lr 0.000941 | 52.47 ms | loss 0.02398 | ppl     1.02\n",
      "| epoch   3 |   849/ 1416 batches | lr 0.000941 | 52.21 ms | loss 0.03644 | ppl     1.04\n",
      "| epoch   3 |  1132/ 1416 batches | lr 0.000941 | 52.17 ms | loss 0.00750 | ppl     1.01\n",
      "| epoch   3 |  1415/ 1416 batches | lr 0.000941 | 52.46 ms | loss 0.02916 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 81.12s | valid loss 0.10080 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   283/ 1416 batches | lr 0.000922 | 52.64 ms | loss 0.00830 | ppl     1.01\n",
      "| epoch   4 |   566/ 1416 batches | lr 0.000922 | 52.22 ms | loss 0.02019 | ppl     1.02\n",
      "| epoch   4 |   849/ 1416 batches | lr 0.000922 | 52.23 ms | loss 0.03649 | ppl     1.04\n",
      "| epoch   4 |  1132/ 1416 batches | lr 0.000922 | 52.44 ms | loss 0.00739 | ppl     1.01\n",
      "| epoch   4 |  1415/ 1416 batches | lr 0.000922 | 52.17 ms | loss 0.03023 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 81.02s | valid loss 0.10037 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   283/ 1416 batches | lr 0.000904 | 52.36 ms | loss 0.00862 | ppl     1.01\n",
      "| epoch   5 |   566/ 1416 batches | lr 0.000904 | 52.16 ms | loss 0.01867 | ppl     1.02\n",
      "| epoch   5 |   849/ 1416 batches | lr 0.000904 | 52.47 ms | loss 0.03132 | ppl     1.03\n",
      "| epoch   5 |  1132/ 1416 batches | lr 0.000904 | 52.22 ms | loss 0.00795 | ppl     1.01\n",
      "| epoch   5 |  1415/ 1416 batches | lr 0.000904 | 52.43 ms | loss 0.02501 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 80.92s | valid loss 0.10040 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   283/ 1416 batches | lr 0.000886 | 52.35 ms | loss 0.00808 | ppl     1.01\n",
      "| epoch   6 |   566/ 1416 batches | lr 0.000886 | 52.43 ms | loss 0.01451 | ppl     1.01\n",
      "| epoch   6 |   849/ 1416 batches | lr 0.000886 | 52.21 ms | loss 0.02738 | ppl     1.03\n",
      "| epoch   6 |  1132/ 1416 batches | lr 0.000886 | 52.46 ms | loss 0.01083 | ppl     1.01\n",
      "| epoch   6 |  1415/ 1416 batches | lr 0.000886 | 52.22 ms | loss 0.02506 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 80.95s | valid loss 0.10009 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   283/ 1416 batches | lr 0.000868 | 52.71 ms | loss 0.00958 | ppl     1.01\n",
      "| epoch   7 |   566/ 1416 batches | lr 0.000868 | 52.22 ms | loss 0.01873 | ppl     1.02\n",
      "| epoch   7 |   849/ 1416 batches | lr 0.000868 | 52.40 ms | loss 0.03395 | ppl     1.03\n",
      "| epoch   7 |  1132/ 1416 batches | lr 0.000868 | 52.14 ms | loss 0.01080 | ppl     1.01\n",
      "| epoch   7 |  1415/ 1416 batches | lr 0.000868 | 52.19 ms | loss 0.02603 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 81.00s | valid loss 0.10052 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   283/ 1416 batches | lr 0.000851 | 52.37 ms | loss 0.00853 | ppl     1.01\n",
      "| epoch   8 |   566/ 1416 batches | lr 0.000851 | 52.45 ms | loss 0.01874 | ppl     1.02\n",
      "| epoch   8 |   849/ 1416 batches | lr 0.000851 | 52.10 ms | loss 0.03525 | ppl     1.04\n",
      "| epoch   8 |  1132/ 1416 batches | lr 0.000851 | 52.20 ms | loss 0.00917 | ppl     1.01\n",
      "| epoch   8 |  1415/ 1416 batches | lr 0.000851 | 52.34 ms | loss 0.03041 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 80.88s | valid loss 0.10052 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   283/ 1416 batches | lr 0.000834 | 52.60 ms | loss 0.00829 | ppl     1.01\n",
      "| epoch   9 |   566/ 1416 batches | lr 0.000834 | 52.10 ms | loss 0.02195 | ppl     1.02\n",
      "| epoch   9 |   849/ 1416 batches | lr 0.000834 | 52.05 ms | loss 0.03056 | ppl     1.03\n",
      "| epoch   9 |  1132/ 1416 batches | lr 0.000834 | 52.29 ms | loss 0.00693 | ppl     1.01\n",
      "| epoch   9 |  1415/ 1416 batches | lr 0.000834 | 52.04 ms | loss 0.02515 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 80.83s | valid loss 0.10079 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   283/ 1416 batches | lr 0.000817 | 52.25 ms | loss 0.00811 | ppl     1.01\n",
      "| epoch  10 |   566/ 1416 batches | lr 0.000817 | 52.04 ms | loss 0.02598 | ppl     1.03\n",
      "| epoch  10 |   849/ 1416 batches | lr 0.000817 | 52.34 ms | loss 0.03024 | ppl     1.03\n",
      "| epoch  10 |  1132/ 1416 batches | lr 0.000817 | 51.98 ms | loss 0.00609 | ppl     1.01\n",
      "| epoch  10 |  1415/ 1416 batches | lr 0.000817 | 52.09 ms | loss 0.02540 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 80.72s | valid loss 0.10052 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   283/ 1416 batches | lr 0.000801 | 52.22 ms | loss 0.00766 | ppl     1.01\n",
      "| epoch  11 |   566/ 1416 batches | lr 0.000801 | 52.25 ms | loss 0.02658 | ppl     1.03\n",
      "| epoch  11 |   849/ 1416 batches | lr 0.000801 | 52.02 ms | loss 0.03249 | ppl     1.03\n",
      "| epoch  11 |  1132/ 1416 batches | lr 0.000801 | 52.04 ms | loss 0.00715 | ppl     1.01\n",
      "| epoch  11 |  1415/ 1416 batches | lr 0.000801 | 52.31 ms | loss 0.02995 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 80.72s | valid loss 0.10100 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   283/ 1416 batches | lr 0.000785 | 52.46 ms | loss 0.00858 | ppl     1.01\n",
      "| epoch  12 |   566/ 1416 batches | lr 0.000785 | 52.02 ms | loss 0.03205 | ppl     1.03\n",
      "| epoch  12 |   849/ 1416 batches | lr 0.000785 | 52.01 ms | loss 0.03734 | ppl     1.04\n",
      "| epoch  12 |  1132/ 1416 batches | lr 0.000785 | 52.31 ms | loss 0.00847 | ppl     1.01\n",
      "| epoch  12 |  1415/ 1416 batches | lr 0.000785 | 52.05 ms | loss 0.03210 | ppl     1.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 80.77s | valid loss 0.10092 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   283/ 1416 batches | lr 0.000769 | 52.26 ms | loss 0.00933 | ppl     1.01\n",
      "| epoch  13 |   566/ 1416 batches | lr 0.000769 | 52.07 ms | loss 0.03091 | ppl     1.03\n",
      "| epoch  13 |   849/ 1416 batches | lr 0.000769 | 52.32 ms | loss 0.04006 | ppl     1.04\n",
      "| epoch  13 |  1132/ 1416 batches | lr 0.000769 | 52.01 ms | loss 0.00920 | ppl     1.01\n",
      "| epoch  13 |  1415/ 1416 batches | lr 0.000769 | 52.05 ms | loss 0.03559 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 80.72s | valid loss 0.10084 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   283/ 1416 batches | lr 0.000754 | 52.30 ms | loss 0.01038 | ppl     1.01\n",
      "| epoch  14 |   566/ 1416 batches | lr 0.000754 | 52.27 ms | loss 0.03138 | ppl     1.03\n",
      "| epoch  14 |   849/ 1416 batches | lr 0.000754 | 52.01 ms | loss 0.04194 | ppl     1.04\n",
      "| epoch  14 |  1132/ 1416 batches | lr 0.000754 | 52.01 ms | loss 0.01124 | ppl     1.01\n",
      "| epoch  14 |  1415/ 1416 batches | lr 0.000754 | 52.26 ms | loss 0.03824 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 80.67s | valid loss 0.10091 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   283/ 1416 batches | lr 0.000739 | 52.45 ms | loss 0.01230 | ppl     1.01\n",
      "| epoch  15 |   566/ 1416 batches | lr 0.000739 | 51.96 ms | loss 0.03422 | ppl     1.03\n",
      "| epoch  15 |   849/ 1416 batches | lr 0.000739 | 51.96 ms | loss 0.04387 | ppl     1.04\n",
      "| epoch  15 |  1132/ 1416 batches | lr 0.000739 | 52.26 ms | loss 0.01649 | ppl     1.02\n",
      "| epoch  15 |  1415/ 1416 batches | lr 0.000739 | 52.01 ms | loss 0.04017 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 80.69s | valid loss 0.10099 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   283/ 1416 batches | lr 0.000724 | 52.16 ms | loss 0.01236 | ppl     1.01\n",
      "| epoch  16 |   566/ 1416 batches | lr 0.000724 | 52.05 ms | loss 0.03479 | ppl     1.04\n",
      "| epoch  16 |   849/ 1416 batches | lr 0.000724 | 53.10 ms | loss 0.04591 | ppl     1.05\n",
      "| epoch  16 |  1132/ 1416 batches | lr 0.000724 | 57.41 ms | loss 0.01907 | ppl     1.02\n",
      "| epoch  16 |  1415/ 1416 batches | lr 0.000724 | 57.94 ms | loss 0.03894 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 85.61s | valid loss 0.10117 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   283/ 1416 batches | lr 0.000709 | 57.59 ms | loss 0.01294 | ppl     1.01\n",
      "| epoch  17 |   566/ 1416 batches | lr 0.000709 | 57.63 ms | loss 0.03415 | ppl     1.03\n",
      "| epoch  17 |   849/ 1416 batches | lr 0.000709 | 57.61 ms | loss 0.04569 | ppl     1.05\n",
      "| epoch  17 |  1132/ 1416 batches | lr 0.000709 | 58.49 ms | loss 0.00646 | ppl     1.01\n",
      "| epoch  17 |  1415/ 1416 batches | lr 0.000709 | 57.43 ms | loss 0.03599 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 90.26s | valid loss 0.10055 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   283/ 1416 batches | lr 0.000695 | 56.71 ms | loss 0.00913 | ppl     1.01\n",
      "| epoch  18 |   566/ 1416 batches | lr 0.000695 | 55.50 ms | loss 0.02871 | ppl     1.03\n",
      "| epoch  18 |   849/ 1416 batches | lr 0.000695 | 58.14 ms | loss 0.03842 | ppl     1.04\n",
      "| epoch  18 |  1132/ 1416 batches | lr 0.000695 | 57.86 ms | loss 0.00992 | ppl     1.01\n",
      "| epoch  18 |  1415/ 1416 batches | lr 0.000695 | 57.76 ms | loss 0.03757 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 89.69s | valid loss 0.10116 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   283/ 1416 batches | lr 0.000681 | 57.91 ms | loss 0.01159 | ppl     1.01\n",
      "| epoch  19 |   566/ 1416 batches | lr 0.000681 | 57.63 ms | loss 0.03438 | ppl     1.03\n",
      "| epoch  19 |   849/ 1416 batches | lr 0.000681 | 57.16 ms | loss 0.04728 | ppl     1.05\n",
      "| epoch  19 |  1132/ 1416 batches | lr 0.000681 | 57.67 ms | loss 0.02294 | ppl     1.02\n",
      "| epoch  19 |  1415/ 1416 batches | lr 0.000681 | 57.40 ms | loss 0.04236 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 88.71s | valid loss 0.10109 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   283/ 1416 batches | lr 0.000668 | 54.65 ms | loss 0.01700 | ppl     1.02\n",
      "| epoch  20 |   566/ 1416 batches | lr 0.000668 | 57.26 ms | loss 0.03552 | ppl     1.04\n",
      "| epoch  20 |   849/ 1416 batches | lr 0.000668 | 51.85 ms | loss 0.04921 | ppl     1.05\n",
      "| epoch  20 |  1132/ 1416 batches | lr 0.000668 | 52.08 ms | loss 0.02281 | ppl     1.02\n",
      "| epoch  20 |  1415/ 1416 batches | lr 0.000668 | 52.53 ms | loss 0.04233 | ppl     1.04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 881.66s | valid loss 0.10102 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   283/ 1416 batches | lr 0.000654 | 58.51 ms | loss 0.01541 | ppl     1.02\n",
      "| epoch  21 |   566/ 1416 batches | lr 0.000654 | 57.41 ms | loss 0.03631 | ppl     1.04\n",
      "| epoch  21 |   849/ 1416 batches | lr 0.000654 | 57.42 ms | loss 0.05309 | ppl     1.05\n",
      "| epoch  21 |  1132/ 1416 batches | lr 0.000654 | 57.92 ms | loss 0.01112 | ppl     1.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     16\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# epoch = 5 일 때마다 val_loss를 구하고, predict_future를 그린다.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         test_result, truth, val_loss \u001b[38;5;241m=\u001b[39m plot_and_loss(model, val_data)\n",
      "Cell \u001b[1;32mIn[9], line 164\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m    161\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    162\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 164\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_data) \u001b[38;5;241m/\u001b[39m batch_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m batch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data, val_data = get_data()\n",
    "from function_file.ML_functions import make_dataframe\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.001\n",
    "model = TransAm().to(device)\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 100 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_data)\n",
    "    \n",
    "    \n",
    "    if (epoch % 20 == 0):\n",
    "        # epoch = 5 일 때마다 val_loss를 구하고, predict_future를 그린다.\n",
    "        test_result, truth, val_loss = plot_and_loss(model, val_data)\n",
    "        #predict_future(model, val_data,60)\n",
    "    else:\n",
    "        # epoch = 5의 배수가 아닐때마다는 evalute를 사용\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        \n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    #if val_loss < best_val_loss:\n",
    "    #    best_val_loss = val_loss\n",
    "    #    best_model = model\n",
    "\n",
    "    scheduler.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+tw]\n",
    "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "from function_file.ML_functions import make_dataframe\n",
    "\n",
    "def get_data():\n",
    "    time        = np.arange(0, 400, 0.1) # 4000 sample\n",
    "    amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    #amplitude = scaler.fit_transform(df.reshape(-1, 1)).reshape(-1)\n",
    "    #from pandas import read_csv\n",
    "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "    _, df = make_dataframe(60,20)\n",
    "    df = df['TEMP'].values   \n",
    "    \n",
    "    train_len = int(len(df) * 0.8)\n",
    "    train_data = df[:train_len] \n",
    "    test_data = df[train_len:] \n",
    "    train_data = scaler_train.fit_transform(train_data.reshape(-1,1)).reshape(-1)\n",
    "    test_data = scaler_test.fit_transform(test_data.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment.. \n",
    "    train_sequence = create_inout_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window] #todo: fix hack?\n",
    "\n",
    "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
    "    test_data = create_inout_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window] #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device),test_data.to(device)\n",
    "\n",
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]    \n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([531726, 2, 100]), torch.Size([132850, 2, 100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = get_data()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransAm().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 512, 1]), torch.Size([100, 512, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "data,target = get_batch(train, 0, 512)\n",
    "data.shape, target.shape # [input_window, batch_size, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "output = model(data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 250])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 5000\n",
    "d_model = 250\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "pe1= pe.unsqueeze(0).transpose(0, 1)\n",
    "pe1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 250])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 5000\n",
    "d_model = 250\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "pe2 = pe.unsqueeze(1)\n",
    "pe2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 :  0.9495403624764921\n",
      "MAE :  6.884691874525865\n",
      "RMSE :  9.072923252313494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r2 : \", r2_score(truth, test_result))\n",
    "print(\"MAE : \", mean_absolute_error(truth, test_result))\n",
    "print(\"RMSE : \", mean_squared_error(truth, test_result)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4]],\n",
       "\n",
       "        [[ 5,  6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11, 12]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.array([[1,2,3,4],[5,6,7,8],\n",
    "                [9,10,11,12]])\n",
    "tmp = torch.from_numpy(tmp)\n",
    "tmp = tmp.unsqueeze(0)\n",
    "tmp = tmp.transpose(1,0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4]],\n",
       "\n",
       "        [[ 5,  6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11, 12]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = np.array([[1,2,3,4],[5,6,7,8],\n",
    "                [9,10,11,12]])\n",
    "tmp1 = torch.from_numpy(tmp1)\n",
    "tmp1 = tmp1.unsqueeze(1)\n",
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
