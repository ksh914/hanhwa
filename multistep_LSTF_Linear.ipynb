{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_functions import make_dataframe\n",
    "\n",
    "_, df = make_dataframe(60,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in range(1,12):\n",
    "    TIME = pd.DataFrame({'label' : [i] * 60436})\n",
    "    globals()['df_'+str(i)] = df[60436*(i-1):60436*i].reset_index(drop=True)\n",
    "    globals()['df_'+str(i)] = pd.concat([globals()['df_'+str(i)], TIME], axis = 1)\n",
    "    globals()['df_'+str(i)].drop(columns = 'TIME', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride = stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size-1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim = 1)\n",
    "        x = self.avg(x.permute(0,2,1))\n",
    "        x = x.permute(0,2,1)\n",
    "        return x\n",
    "    \n",
    "class series_decomp(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "    \n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    \"\"\" D-Linear \"\"\"\n",
    "\n",
    "    def __init__(self, window_size, forecast_size, feature_size, kernel_size = 25, individual = False):\n",
    "        super(DLinear, self).__init__()\n",
    "\n",
    "        self.seq_len = window_size\n",
    "        self.pred_len = forecast_size\n",
    "        self.channels = feature_size\n",
    "        self.decomposition = series_decomp(kernel_size)\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend = nn.ModuleList()\n",
    "\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(nn.Linear(self.seq_len, self.pred_len))\n",
    "                self.Linear_Trend.append(nn.Linear(self.seqlen, self.pred_len))\n",
    "\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.seq_len, self.pred_len)\n",
    "            self.Linear_Trend = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seasonal_init, trend_init = self.decomposition(x)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init(1), self.pred_len], dtype = seasonal_init.dtype).to(seasonal_init.device)\n",
    "            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.pred_len], dtype = trend_init.dtype).to(trend_init.device)\n",
    "\n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:, i, :] = self.Linear_Seasonal[i](seasonal_init[:, i, :])\n",
    "                trend_output[:, i, :] = self.Linear_Trend[i](trend_init[:, i, :])\n",
    "\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0,2,1) # to [Batch_size, Output Length, Channel]\n",
    "    \n",
    "\n",
    "class NLinear(nn.Module):\n",
    "    def __init__(self, window_size, forecast_size, feature_size, individual = False):\n",
    "        super(NLinear, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.forecast_size = forecast_size\n",
    "        self.channels = feature_size\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.individual:\n",
    "            self.Linear = torch.nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(torch.nn.Linear(self.window_size, self.forecast_size))\n",
    "\n",
    "        else:\n",
    "            self.Linear = torch.nn.Linear(self.window_size, self.forecast_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_last = x[:, -1:, :].detach()\n",
    "        x = x-seq_last\n",
    "\n",
    "        if self.individual:\n",
    "            output = torch.zeros([x.size(0), self.forecast_size, x.size(2)],dtype = x.dtype).to(x.device)\n",
    "            for i in range(self.channels):\n",
    "                output[:, :, i] = self.Linear[i](x[:, :, i])\n",
    "            x = output\n",
    "        else:\n",
    "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "        x = x + seq_last\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "def targetParsing(data, target, index = False):\n",
    "    if index == False:\n",
    "        result = data.loc[:, target]\n",
    "    else:\n",
    "        result = data.iloc[:, target]\n",
    "    \n",
    "    return list(result.index), result.to_numpy()\n",
    "\n",
    "def transform(raw, check_inverse=False):\n",
    "    data = raw.reshape(-1,1)\n",
    "    if check_inverse == False:\n",
    "        return scaler.fit_transform(data)\n",
    "    else:\n",
    "        return scaler.inverse_transform(data)[:, 0]\n",
    "    \n",
    "class WindowDataset(Dataset):\n",
    "    def __init__(self,y, input_window, output_window, stride = 1):\n",
    "        L = y.shape[0]\n",
    "         \n",
    "        # Stride 씩 움직일 때 마다 생기는 총 sample 개수 \n",
    "        num_samples = (L - input_window - output_window) // stride + 1\n",
    "\n",
    "        X,Y = np.zeros([input_window, num_samples]), np.zeros([output_window, num_samples])\n",
    "\n",
    "        for i in np.arange(num_samples):\n",
    "            start_x = stride * i\n",
    "            end_x = start_x + input_window\n",
    "            X[:, i] = y[start_x : end_x]\n",
    "\n",
    "            start_y = stride*i + input_window\n",
    "            end_y = start_y + output_window\n",
    "\n",
    "            Y[:, i] = y[start_y : end_y]\n",
    "\n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1).transpose((1,0,2)) # X : (num_samples, input_window, 1)\n",
    "        Y = Y.reshape(Y.shape[0], Y.shape[1], 1).transpose((1,0,2)) # Y : (num_samples, output_window, 1)\n",
    "\n",
    "        self.X, self.Y = X, Y\n",
    "    def __len__(self):\n",
    "        return len(self.X) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "def customDataLoader(data, window_size:int, forecast_size : int, batch_size:int):\n",
    "    train = transform(data)[:-window_size, 0]\n",
    "    dataset = WindowDataset(train, window_size, forecast_size)\n",
    "    result = DataLoader(dataset, batch_size = batch_size)\n",
    "    return result\n",
    "\n",
    "class trainer():\n",
    "    def __init__(self, data, dataloader, window_size, forecast_size, name='DLinear',feature_size=1 ,lr = 0.001):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "        self.data = data\n",
    "        self.trains = transform(data)[:-window_size, 0]\n",
    "        self.dataloader = dataloader\n",
    "        self.window_size = window_size\n",
    "        self.forecast_size = forecast_size\n",
    "\n",
    "        if name == 'DLinear':\n",
    "            self.model = DLinear(window_size, forecast_size).to(self.device)\n",
    "        else:\n",
    "            self.model = NLinear(window_size, forecast_size).to(self.device)\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        self.name = name\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(paras = self.model.parameters(), lr = lr)\n",
    "\n",
    "    def train(self, epoch = 50):\n",
    "        self.model.train()\n",
    "        progress = tqdm(range(epoch))\n",
    "        loss_list = []\n",
    "\n",
    "        for _ in progress:\n",
    "            batch_loss = 0.0\n",
    "\n",
    "            for (inputs, outputs) in self.dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(inputs.float().to(self.device))\n",
    "                loss = self.criterion(output, outputs.float().to(self.device))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                back_loss += loss.item()\n",
    "\n",
    "            loss_list.append(batch_loss.cpu())\n",
    "            progress.set_description(\"loss : {:0.6f}\".format(batch_loss.cpu().item() / len(self.dataloader)))\n",
    "        plt.plot(loss_list)\n",
    "\n",
    "    def evaluate(self):\n",
    "        window_size = self.window_size\n",
    "        input = torch.tensor(self.trains[-window_size:]).reshape(1,-1,1).float().to(self.device)\n",
    "        self.model.eval()\n",
    "        predictions = self.model(input)\n",
    "        return predictions.detach().cpu().numpy()\n",
    "\n",
    "    def implement(self):\n",
    "        process = trainer(self.data, self.dataloader, self.window_size, self.forecast_size, self.feature_size, self.name)\n",
    "        process.train()\n",
    "        evaluate = process.evaluate()\n",
    "        result = transform(evaluate, check_inverse=True)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "def figureplot(date,data,pred,window_size,forecast_size):\n",
    "    datenum=mdates.date2num(date)\n",
    "    len=data.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    ax.plot(datenum[len-window_size:len], data[len-window_size:], label=\"Real\")\n",
    "    ax.plot(datenum[len-forecast_size:len], pred, label=\"LSTM-linear\")\n",
    "    locator = mdates.AutoDateLocator()\n",
    "    formatter = mdates.AutoDateFormatter(locator)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=pd.read_csv('./서인천IC-부평IC 평균속도.csv',encoding='CP949').set_index('집계일시').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date, data = targetParsing(raw, 0, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "forecast_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = customDataLoader(data, window_size, forecast_size, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98.63, 100.53,  99.86,  99.34,  93.64,  93.92,  91.78,  90.57,\n",
       "        87.03,  81.75,  77.13,  76.01,  76.09,  46.5 ,  56.69,  54.91,\n",
       "        67.57,  69.82,  79.98,  82.14,  81.02,  82.58,  85.55,  91.8 ,\n",
       "        91.87,  93.9 ,  95.61,  96.73,  94.15,  99.36, 100.24,  97.64,\n",
       "        94.25,  90.01,  86.25,  86.81,  88.37,  85.6 ,  84.18,  83.35,\n",
       "        81.26,  77.43,  84.89,  84.12,  81.19,  85.15,  93.34,  98.84,\n",
       "       100.22, 100.22,  98.65,  97.45,  95.32,  89.67,  75.37,  48.91,\n",
       "        48.06,  58.29,  70.01,  74.31,  76.01,  74.91,  69.59,  64.77,\n",
       "        78.63,  64.41,  51.38,  59.73,  77.89,  85.24,  90.58,  97.63,\n",
       "        99.36,  98.24,  96.13,  93.54,  92.1 ,  90.03,  77.64,  61.32,\n",
       "        59.25,  59.08,  58.55,  56.2 ,  68.7 ,  63.62,  55.86,  57.99,\n",
       "        61.51,  62.23,  56.89,  48.77,  65.57,  75.84,  78.58,  89.09,\n",
       "        97.29,  96.91,  96.52,  95.49,  93.89,  94.44,  92.  ,  91.81,\n",
       "        90.23,  86.25,  84.58,  81.55,  84.2 ,  84.33,  82.21,  77.65,\n",
       "        74.94,  63.52,  76.63,  82.82,  81.88,  85.35,  92.32,  99.38,\n",
       "        99.84,  98.49,  97.71,  95.44,  93.42,  89.9 ,  77.13,  60.78,\n",
       "        50.99,  56.71,  59.93,  61.96,  74.9 ,  73.06,  69.86,  60.16,\n",
       "        59.89,  62.14,  54.64,  61.05,  77.64,  83.05,  91.67,  98.61,\n",
       "        97.89,  98.09,  97.26,  94.52,  92.54,  89.01,  80.73,  64.29,\n",
       "        48.07,  54.16,  59.72,  60.53,  75.52,  74.46,  63.78,  62.15,\n",
       "        62.71,  63.77,  47.37,  54.05,  76.93,  81.89,  87.31,  95.84,\n",
       "       100.2 , 101.5 ,  99.14,  96.68,  94.05,  92.86,  89.26,  88.16,\n",
       "        83.08,  77.57,  74.28,  67.08,  61.82,  66.73,  68.46,  57.55,\n",
       "        59.83,  58.15,  57.79,  87.15,  79.88,  80.55,  86.88,  96.88,\n",
       "        99.82, 101.96, 102.98, 100.55,  98.87, 103.1 , 102.05,  99.56,\n",
       "        96.12,  91.27,  85.26,  85.31,  84.06,  85.31,  84.1 ,  80.42,\n",
       "        74.76,  78.25,  84.72,  85.11,  81.88,  84.99,  93.07,  98.86,\n",
       "       101.02, 101.77,  97.69,  97.75,  93.56,  85.61,  65.05,  56.97,\n",
       "        53.41,  55.28,  57.77,  53.15,  68.05,  70.2 ,  71.08,  69.06,\n",
       "        67.13,  54.6 ,  47.1 ,  71.28,  80.83,  86.99,  91.58,  97.08,\n",
       "        99.22,  98.04,  98.25,  92.89,  91.96,  88.33,  59.85,  22.89,\n",
       "        62.62,  52.42,  56.  ,  71.34,  75.84,  72.04,  67.1 ,  67.34,\n",
       "        61.64,  60.43,  51.79,  60.76,  78.15,  83.06,  88.96,  95.71,\n",
       "        97.  ,  96.6 ,  95.97,  94.68,  91.98,  88.81,  77.82,  64.24,\n",
       "        52.35,  55.27,  56.89,  68.25,  75.11,  73.72,  69.65,  58.68,\n",
       "        64.01,  63.41,  54.51,  56.3 ,  80.92,  84.74,  89.63,  98.34,\n",
       "       100.3 , 100.18, 100.04,  94.82,  93.11,  88.75,  79.02,  64.23,\n",
       "        55.11,  58.39,  58.1 ,  71.91,  76.03,  74.03,  70.97,  63.27,\n",
       "        60.  ,  61.34,  43.87,  59.25,  91.77,  84.06,  89.72,  97.98,\n",
       "        99.62,  97.43,  98.33,  93.55,  92.32,  88.84,  78.89,  67.14,\n",
       "        60.52,  65.  ,  59.85,  72.5 ,  75.21,  71.38,  62.86,  59.42,\n",
       "        62.6 ,  62.77,  46.64,  48.35,  76.3 ,  82.56,  86.4 ,  95.89,\n",
       "        98.76,  99.67,  98.56,  97.23,  93.07,  93.16,  92.59,  89.72,\n",
       "        81.26,  78.71,  74.35,  76.12,  67.96,  52.67,  56.94,  52.05,\n",
       "        58.48,  55.59,  69.36,  78.64,  77.14,  78.64,  85.68,  88.36,\n",
       "        88.55,  95.66,  92.35,  89.91,  83.93,  89.53,  90.78,  92.61,\n",
       "        91.9 ,  84.51,  83.7 ,  81.89,  79.33,  78.21,  76.66,  71.22,\n",
       "        72.39,  79.34,  76.27,  77.23,  80.26,  83.06,  87.7 ,  93.96,\n",
       "        96.02,  94.89,  90.78,  89.25,  89.87,  86.55,  72.12,  53.31,\n",
       "        43.31,  55.5 ,  56.83,  57.16,  61.52,  72.34,  68.06,  67.44,\n",
       "        63.44,  55.97,  55.08,  74.04,  79.2 ,  85.82,  91.53,  98.19,\n",
       "       100.41,  98.55,  98.23,  95.63,  91.82,  89.3 ,  82.23,  67.75,\n",
       "        51.97,  68.6 ,  70.61,  65.95,  73.61,  71.9 ,  65.01,  63.5 ,\n",
       "        59.33,  60.75,  50.94,  54.99,  75.83,  81.73,  86.8 ,  96.27,\n",
       "       100.41, 101.66, 101.87,  96.52,  94.2 ,  94.38,  91.76,  91.44,\n",
       "        88.23,  82.81,  82.02,  83.31,  83.41,  82.15,  81.63,  80.2 ,\n",
       "        75.2 ,  68.28,  79.27,  87.23,  82.81,  85.74,  89.64,  99.  ,\n",
       "       102.54, 100.  ,  98.04,  94.87,  92.9 ,  88.98,  77.  ,  61.2 ,\n",
       "        53.14,  56.96,  58.37,  61.42,  71.38,  71.6 ,  67.48,  67.14,\n",
       "        57.27,  59.18,  50.17,  55.14,  70.97,  77.71,  82.37,  92.83,\n",
       "        92.95,  94.71,  88.33,  87.18,  84.96,  82.13,  71.1 ,  60.49,\n",
       "        61.03,  59.34,  59.19,  58.63,  72.69,  72.18,  66.17,  57.31,\n",
       "        56.57,  59.4 ,  52.34,  63.66,  78.04,  82.01,  86.57,  95.42,\n",
       "        99.71, 102.07,  97.75,  96.06,  94.91,  94.93,  90.27,  89.8 ,\n",
       "        82.95,  76.03,  73.71,  77.34,  77.85,  74.96,  78.  ,  73.28,\n",
       "        73.38,  61.57,  74.22,  85.02,  82.65,  83.6 ,  88.44,  96.62,\n",
       "        99.84, 102.08,  99.64, 101.46,  99.86, 104.52, 103.03, 100.55,\n",
       "        97.97,  90.75,  88.26,  88.15,  87.25,  86.15,  85.26,  83.88,\n",
       "        80.95,  82.97,  88.77,  89.08,  85.44,  88.68,  94.45,  99.29,\n",
       "       101.03, 100.95, 100.02,  96.39,  95.  ,  89.76,  75.75,  63.11,\n",
       "        53.75,  57.98,  70.74,  76.17,  77.52,  75.82,  73.59,  73.76,\n",
       "        63.25,  63.97,  54.48,  67.79,  78.53,  87.15,  92.29,  97.78,\n",
       "       100.35,  98.32,  95.51,  94.47,  92.18,  81.85,  67.18,  60.99,\n",
       "        61.73,  58.66,  59.96,  72.55,  76.21,  72.18,  69.98,  69.11,\n",
       "        62.85,  58.03,  55.31,  65.07,  78.82,  84.67,  90.31,  97.55,\n",
       "        99.66,  99.25,  98.23,  94.18,  92.47,  88.82,  76.95,  50.49,\n",
       "        56.  ,  63.21,  64.93,  72.46,  74.9 ,  74.58,  69.83,  66.83,\n",
       "        56.82,  60.5 ,  53.79,  60.34,  80.21,  84.49,  89.55,  98.14,\n",
       "       101.46, 100.41,  98.56,  94.05,  92.56,  88.84,  67.73,  60.65,\n",
       "        59.63,  58.69,  57.47,  59.02,  74.64,  74.04,  72.18,  71.34,\n",
       "        66.47,  58.8 ,  57.64,  75.44,  80.86,  85.21,  89.77,  97.16,\n",
       "        99.25,  99.41,  95.93,  92.86,  84.54,  78.81,  70.78,  59.04,\n",
       "        59.68,  60.53,  58.41,  65.68,  75.04,  73.76,  69.4 ,  70.65,\n",
       "        74.23,  63.07,  52.51,  61.28,  79.35,  83.49,  88.42,  96.29,\n",
       "        98.83, 100.6 , 100.06,  96.94,  94.82,  94.58,  91.16,  89.83,\n",
       "        82.74,  78.32,  75.12,  73.  ,  70.06,  56.31,  80.22,  63.39,\n",
       "        56.7 ,  56.5 ,  72.06,  84.26,  85.31,  86.52,  89.11,  96.48,\n",
       "       100.77, 101.28, 100.32,  99.52,  98.76, 104.14, 101.85,  99.51,\n",
       "        95.53,  89.91,  86.06,  84.07,  83.45,  81.84,  82.53,  80.48,\n",
       "        80.22,  80.38,  78.89,  70.32,  80.91,  78.54,  74.73,  87.96,\n",
       "        91.57,  91.3 ,  92.97,  90.54,  91.95,  87.19,  74.45,  81.51,\n",
       "        78.97,  51.45,  70.52,  71.16,  77.21,  69.64,  53.45,  57.62,\n",
       "        61.12,  63.06,  56.01,  58.86,  79.86,  86.01,  92.28,  97.76])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9278],\n",
      "         [0.9511],\n",
      "         [0.9429],\n",
      "         [0.9365],\n",
      "         [0.8667],\n",
      "         [0.8701],\n",
      "         [0.8439],\n",
      "         [0.8291],\n",
      "         [0.7857],\n",
      "         [0.7211],\n",
      "         [0.6645],\n",
      "         [0.6507],\n",
      "         [0.6517],\n",
      "         [0.2892],\n",
      "         [0.4141],\n",
      "         [0.3923],\n",
      "         [0.5473],\n",
      "         [0.5749],\n",
      "         [0.6994],\n",
      "         [0.7258],\n",
      "         [0.7121],\n",
      "         [0.7312],\n",
      "         [0.7676],\n",
      "         [0.8442],\n",
      "         [0.8450],\n",
      "         [0.8699],\n",
      "         [0.8908],\n",
      "         [0.9046],\n",
      "         [0.8730],\n",
      "         [0.9368],\n",
      "         [0.9476],\n",
      "         [0.9157],\n",
      "         [0.8742],\n",
      "         [0.8222],\n",
      "         [0.7762],\n",
      "         [0.7830],\n",
      "         [0.8022],\n",
      "         [0.7682],\n",
      "         [0.7508],\n",
      "         [0.7407],\n",
      "         [0.7151],\n",
      "         [0.6681],\n",
      "         [0.7595],\n",
      "         [0.7501],\n",
      "         [0.7142],\n",
      "         [0.7627],\n",
      "         [0.8630],\n",
      "         [0.9304],\n",
      "         [0.9473],\n",
      "         [0.9473],\n",
      "         [0.9281],\n",
      "         [0.9134],\n",
      "         [0.8873],\n",
      "         [0.8181],\n",
      "         [0.6429],\n",
      "         [0.3188],\n",
      "         [0.3083],\n",
      "         [0.4337],\n",
      "         [0.5772],\n",
      "         [0.6299]],\n",
      "\n",
      "        [[0.9511],\n",
      "         [0.9429],\n",
      "         [0.9365],\n",
      "         [0.8667],\n",
      "         [0.8701],\n",
      "         [0.8439],\n",
      "         [0.8291],\n",
      "         [0.7857],\n",
      "         [0.7211],\n",
      "         [0.6645],\n",
      "         [0.6507],\n",
      "         [0.6517],\n",
      "         [0.2892],\n",
      "         [0.4141],\n",
      "         [0.3923],\n",
      "         [0.5473],\n",
      "         [0.5749],\n",
      "         [0.6994],\n",
      "         [0.7258],\n",
      "         [0.7121],\n",
      "         [0.7312],\n",
      "         [0.7676],\n",
      "         [0.8442],\n",
      "         [0.8450],\n",
      "         [0.8699],\n",
      "         [0.8908],\n",
      "         [0.9046],\n",
      "         [0.8730],\n",
      "         [0.9368],\n",
      "         [0.9476],\n",
      "         [0.9157],\n",
      "         [0.8742],\n",
      "         [0.8222],\n",
      "         [0.7762],\n",
      "         [0.7830],\n",
      "         [0.8022],\n",
      "         [0.7682],\n",
      "         [0.7508],\n",
      "         [0.7407],\n",
      "         [0.7151],\n",
      "         [0.6681],\n",
      "         [0.7595],\n",
      "         [0.7501],\n",
      "         [0.7142],\n",
      "         [0.7627],\n",
      "         [0.8630],\n",
      "         [0.9304],\n",
      "         [0.9473],\n",
      "         [0.9473],\n",
      "         [0.9281],\n",
      "         [0.9134],\n",
      "         [0.8873],\n",
      "         [0.8181],\n",
      "         [0.6429],\n",
      "         [0.3188],\n",
      "         [0.3083],\n",
      "         [0.4337],\n",
      "         [0.5772],\n",
      "         [0.6299],\n",
      "         [0.6507]],\n",
      "\n",
      "        [[0.9429],\n",
      "         [0.9365],\n",
      "         [0.8667],\n",
      "         [0.8701],\n",
      "         [0.8439],\n",
      "         [0.8291],\n",
      "         [0.7857],\n",
      "         [0.7211],\n",
      "         [0.6645],\n",
      "         [0.6507],\n",
      "         [0.6517],\n",
      "         [0.2892],\n",
      "         [0.4141],\n",
      "         [0.3923],\n",
      "         [0.5473],\n",
      "         [0.5749],\n",
      "         [0.6994],\n",
      "         [0.7258],\n",
      "         [0.7121],\n",
      "         [0.7312],\n",
      "         [0.7676],\n",
      "         [0.8442],\n",
      "         [0.8450],\n",
      "         [0.8699],\n",
      "         [0.8908],\n",
      "         [0.9046],\n",
      "         [0.8730],\n",
      "         [0.9368],\n",
      "         [0.9476],\n",
      "         [0.9157],\n",
      "         [0.8742],\n",
      "         [0.8222],\n",
      "         [0.7762],\n",
      "         [0.7830],\n",
      "         [0.8022],\n",
      "         [0.7682],\n",
      "         [0.7508],\n",
      "         [0.7407],\n",
      "         [0.7151],\n",
      "         [0.6681],\n",
      "         [0.7595],\n",
      "         [0.7501],\n",
      "         [0.7142],\n",
      "         [0.7627],\n",
      "         [0.8630],\n",
      "         [0.9304],\n",
      "         [0.9473],\n",
      "         [0.9473],\n",
      "         [0.9281],\n",
      "         [0.9134],\n",
      "         [0.8873],\n",
      "         [0.8181],\n",
      "         [0.6429],\n",
      "         [0.3188],\n",
      "         [0.3083],\n",
      "         [0.4337],\n",
      "         [0.5772],\n",
      "         [0.6299],\n",
      "         [0.6507],\n",
      "         [0.6373]],\n",
      "\n",
      "        [[0.9365],\n",
      "         [0.8667],\n",
      "         [0.8701],\n",
      "         [0.8439],\n",
      "         [0.8291],\n",
      "         [0.7857],\n",
      "         [0.7211],\n",
      "         [0.6645],\n",
      "         [0.6507],\n",
      "         [0.6517],\n",
      "         [0.2892],\n",
      "         [0.4141],\n",
      "         [0.3923],\n",
      "         [0.5473],\n",
      "         [0.5749],\n",
      "         [0.6994],\n",
      "         [0.7258],\n",
      "         [0.7121],\n",
      "         [0.7312],\n",
      "         [0.7676],\n",
      "         [0.8442],\n",
      "         [0.8450],\n",
      "         [0.8699],\n",
      "         [0.8908],\n",
      "         [0.9046],\n",
      "         [0.8730],\n",
      "         [0.9368],\n",
      "         [0.9476],\n",
      "         [0.9157],\n",
      "         [0.8742],\n",
      "         [0.8222],\n",
      "         [0.7762],\n",
      "         [0.7830],\n",
      "         [0.8022],\n",
      "         [0.7682],\n",
      "         [0.7508],\n",
      "         [0.7407],\n",
      "         [0.7151],\n",
      "         [0.6681],\n",
      "         [0.7595],\n",
      "         [0.7501],\n",
      "         [0.7142],\n",
      "         [0.7627],\n",
      "         [0.8630],\n",
      "         [0.9304],\n",
      "         [0.9473],\n",
      "         [0.9473],\n",
      "         [0.9281],\n",
      "         [0.9134],\n",
      "         [0.8873],\n",
      "         [0.8181],\n",
      "         [0.6429],\n",
      "         [0.3188],\n",
      "         [0.3083],\n",
      "         [0.4337],\n",
      "         [0.5772],\n",
      "         [0.6299],\n",
      "         [0.6507],\n",
      "         [0.6373],\n",
      "         [0.5721]]], dtype=torch.float64) tensor([[[0.6507],\n",
      "         [0.6373],\n",
      "         [0.5721],\n",
      "         [0.5130],\n",
      "         [0.6828]],\n",
      "\n",
      "        [[0.6373],\n",
      "         [0.5721],\n",
      "         [0.5130],\n",
      "         [0.6828],\n",
      "         [0.5086]],\n",
      "\n",
      "        [[0.5721],\n",
      "         [0.5130],\n",
      "         [0.6828],\n",
      "         [0.5086],\n",
      "         [0.3490]],\n",
      "\n",
      "        [[0.5130],\n",
      "         [0.6828],\n",
      "         [0.5086],\n",
      "         [0.3490],\n",
      "         [0.4513]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for a,b in dataloader:\n",
    "    print(a,b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
