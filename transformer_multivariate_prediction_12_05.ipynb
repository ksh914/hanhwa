{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sejong\\Desktop\\hanhwa\n"
     ]
    }
   ],
   "source": [
    "cd ./hanhwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'function_file' from 'c:\\\\Users\\\\Sejong\\\\Desktop\\\\hanhwa\\\\function_file\\\\__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import function_file as ff\n",
    "importlib.reload(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len= 5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe) # this stores the variable in the state_dict (used for non-trainable variables)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments : \n",
    "            x : Tensor, shape : [input_window, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, feature_size = 250, num_layers = 1, dropout = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model = feature_size, nhead = 10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers = num_layers)\n",
    "        self.decoder = nn.Linear(feature_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "    \n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "SEED = 96\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "input_window = 30\n",
    "output_window = 10\n",
    "scaler_train = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def create_inout_sequence_2(input_data, input_window, output_window):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - input_window):\n",
    "        train_seq = np.append(input_data[i : i + input_window][:-output_window], output_window * [[0,0]], axis = 0)\n",
    "        train_label = input_data[i : i + input_window]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    df = ff.time_series.time_series_dataframe()\n",
    "    df = df.iloc[:, :2]\n",
    "\n",
    "    train_len = int(len(df) * 0.8)\n",
    "    train_data = df[:train_len]\n",
    "    test_data = df[train_len:]\n",
    "\n",
    "    temp_train = scaler_train.fit_transform(train_data['TEMP'].values.reshape(-1,1)).reshape(-1)\n",
    "    train_data['TEMP'] = temp_train\n",
    "    temp_test = scaler_test.fit_transform(test_data['TEMP'].values.reshape(-1,1)).reshape(-1)\n",
    "    test_data['TEMP'] = temp_test\n",
    "    train_data = train_data.values\n",
    "    test_data = test_data.values\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_sequence = create_inout_sequence_2(train_data, input_window, output_window)\n",
    "    train_sequence = train_sequence[:-output_window]\n",
    "\n",
    "    test_sequence = create_inout_sequence_2(test_data, input_window, output_window)\n",
    "    test_sequence = test_sequence[:-output_window]\n",
    "\n",
    "    return train_sequence.to(device), test_sequence.to(device)\n",
    "\n",
    "\n",
    "def get_batch(source, i, batch_size):\n",
    "    seq_len = min(batch_size, len(source) -1 -i)\n",
    "    data = source[i : i + seq_len]\n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, batch_size):\n",
    "    seq_len = min(batch_size, len(source) -1 -i)\n",
    "    data = source[i : i + seq_len]\n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target\n",
    "\n",
    "train, test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = lr)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "data = train[:seq_len]    \n",
    "input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
    "target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 512, 1, 2]), torch.Size([30, 512, 1, 2]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 250])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 5000\n",
    "d_model = 250\n",
    "pe = torch.zeros(max_len,1, d_model)\n",
    "position = torch.arange(max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "\n",
    "pe[:,0, 0::2] = torch.sin(position * div_term)\n",
    "pe[:,0, 1::2] = torch.cos(position * div_term)\n",
    "pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 250])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pe[:100, :]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionalEncoding(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = PositionalEncoding(250)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
