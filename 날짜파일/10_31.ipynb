{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 9) (1576, 9) (6300,) (1576,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_TEMP</th>\n",
       "      <th>STD</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURT</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>25%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Group</th>\n",
       "      <th>batch_num</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284.192</td>\n",
       "      <td>1.275722</td>\n",
       "      <td>281.401</td>\n",
       "      <td>287.082</td>\n",
       "      <td>0.295874</td>\n",
       "      <td>-0.637850</td>\n",
       "      <td>283.830</td>\n",
       "      <td>283.258</td>\n",
       "      <td>285.130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284.353</td>\n",
       "      <td>1.052731</td>\n",
       "      <td>281.236</td>\n",
       "      <td>286.949</td>\n",
       "      <td>-0.106596</td>\n",
       "      <td>0.698932</td>\n",
       "      <td>284.267</td>\n",
       "      <td>283.797</td>\n",
       "      <td>284.914</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285.276</td>\n",
       "      <td>1.043551</td>\n",
       "      <td>282.941</td>\n",
       "      <td>287.552</td>\n",
       "      <td>-0.194906</td>\n",
       "      <td>-0.650376</td>\n",
       "      <td>285.382</td>\n",
       "      <td>284.480</td>\n",
       "      <td>286.067</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285.589</td>\n",
       "      <td>0.970639</td>\n",
       "      <td>283.867</td>\n",
       "      <td>288.153</td>\n",
       "      <td>0.674937</td>\n",
       "      <td>-0.078318</td>\n",
       "      <td>285.392</td>\n",
       "      <td>284.831</td>\n",
       "      <td>286.155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285.146</td>\n",
       "      <td>1.074865</td>\n",
       "      <td>281.689</td>\n",
       "      <td>286.664</td>\n",
       "      <td>-1.387162</td>\n",
       "      <td>1.773495</td>\n",
       "      <td>285.408</td>\n",
       "      <td>284.652</td>\n",
       "      <td>285.868</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>931.874</td>\n",
       "      <td>2.127380</td>\n",
       "      <td>926.730</td>\n",
       "      <td>936.100</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>-0.390703</td>\n",
       "      <td>931.289</td>\n",
       "      <td>930.506</td>\n",
       "      <td>933.720</td>\n",
       "      <td>11</td>\n",
       "      <td>712</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>933.001</td>\n",
       "      <td>0.585021</td>\n",
       "      <td>931.564</td>\n",
       "      <td>934.166</td>\n",
       "      <td>-0.247556</td>\n",
       "      <td>-0.619292</td>\n",
       "      <td>933.079</td>\n",
       "      <td>932.608</td>\n",
       "      <td>933.400</td>\n",
       "      <td>11</td>\n",
       "      <td>713</td>\n",
       "      <td>7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>933.236</td>\n",
       "      <td>0.659152</td>\n",
       "      <td>931.690</td>\n",
       "      <td>934.549</td>\n",
       "      <td>-0.459517</td>\n",
       "      <td>-0.417622</td>\n",
       "      <td>933.340</td>\n",
       "      <td>932.907</td>\n",
       "      <td>933.744</td>\n",
       "      <td>11</td>\n",
       "      <td>714</td>\n",
       "      <td>7873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7874</th>\n",
       "      <td>933.649</td>\n",
       "      <td>0.771575</td>\n",
       "      <td>932.209</td>\n",
       "      <td>935.319</td>\n",
       "      <td>0.079975</td>\n",
       "      <td>-1.172105</td>\n",
       "      <td>933.754</td>\n",
       "      <td>932.942</td>\n",
       "      <td>934.268</td>\n",
       "      <td>11</td>\n",
       "      <td>715</td>\n",
       "      <td>7874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>933.682</td>\n",
       "      <td>0.496999</td>\n",
       "      <td>932.523</td>\n",
       "      <td>935.378</td>\n",
       "      <td>0.667966</td>\n",
       "      <td>0.893221</td>\n",
       "      <td>933.649</td>\n",
       "      <td>933.359</td>\n",
       "      <td>933.944</td>\n",
       "      <td>11</td>\n",
       "      <td>716</td>\n",
       "      <td>7875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7876 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       "0       284.192  1.275722  281.401  287.082  0.295874 -0.637850  283.830   \n",
       "1       284.353  1.052731  281.236  286.949 -0.106596  0.698932  284.267   \n",
       "2       285.276  1.043551  282.941  287.552 -0.194906 -0.650376  285.382   \n",
       "3       285.589  0.970639  283.867  288.153  0.674937 -0.078318  285.392   \n",
       "4       285.146  1.074865  281.689  286.664 -1.387162  1.773495  285.408   \n",
       "...         ...       ...      ...      ...       ...       ...      ...   \n",
       "7871    931.874  2.127380  926.730  936.100  0.082092 -0.390703  931.289   \n",
       "7872    933.001  0.585021  931.564  934.166 -0.247556 -0.619292  933.079   \n",
       "7873    933.236  0.659152  931.690  934.549 -0.459517 -0.417622  933.340   \n",
       "7874    933.649  0.771575  932.209  935.319  0.079975 -1.172105  933.754   \n",
       "7875    933.682  0.496999  932.523  935.378  0.667966  0.893221  933.649   \n",
       "\n",
       "          25%      75%  Group  batch_num  TIME  \n",
       "0     283.258  285.130      1          1     0  \n",
       "1     283.797  284.914      1          2     1  \n",
       "2     284.480  286.067      1          3     2  \n",
       "3     284.831  286.155      1          4     3  \n",
       "4     284.652  285.868      1          5     4  \n",
       "...       ...      ...    ...        ...   ...  \n",
       "7871  930.506  933.720     11        712  7871  \n",
       "7872  932.608  933.400     11        713  7872  \n",
       "7873  932.907  933.744     11        714  7873  \n",
       "7874  932.942  934.268     11        715  7874  \n",
       "7875  933.359  933.944     11        716  7875  \n",
       "\n",
       "[7876 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 경향성이 있는 그래프의 선형적으로 증가할 수 있게 하는 함수 \n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "# x: 시간축인 함수 plot 함수\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14)\n",
    "    plt.grid(True)\n",
    "\n",
    "# 120개씩 자르는 함수 \n",
    "def univariate_data(dataset, start_index, end_index):\n",
    "    data = []\n",
    "    history_size = 120\n",
    "    start_index = start_index + history_size\n",
    "\n",
    "\n",
    "    for i in range(start_index, end_index, 120): # 0\n",
    "        indices = range(i - history_size, i) # [0 - 120] , [120 - 240] ...\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "for i in range(1,9):\n",
    "    globals()['df_'+str(i) ]= pd.read_csv('./temperature_csv_file/temp_df_{}.csv'.format(i), encoding = 'cp949')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2], axis = 0)\n",
    "df_all = pd.concat([df_all, df_3], axis = 0)\n",
    "df_all = pd.concat([df_all, df_4], axis = 0)\n",
    "df_all = pd.concat([df_all, df_5], axis = 0)\n",
    "df_all = pd.concat([df_all, df_6], axis = 0)\n",
    "df_all = pd.concat([df_all, df_7], axis = 0)\n",
    "df_all = pd.concat([df_all, df_8], axis = 0)\n",
    "\n",
    "df_all = df_all[:601800].reset_index().drop(columns = ['index'], axis = 0)\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_tmp'] = df_all[85920*(i-1):85920*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_tmp']['TEMP'].mean()\n",
    "    diff  = 261.7292228119181 - mean\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_tmp'] = globals()['df_'+str(i-5)+'_tmp'].copy()\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_tmp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_tmp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(85920)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_tmp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] = series\n",
    "\n",
    "\n",
    "univariate_past_history = 120\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : [], 'batch_num' : []}\n",
    "\n",
    "    for j in range(716):\n",
    "        MEAN = np.round(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].mean(),3)\n",
    "        MIN = np.min(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        MAX = np.max(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        STD = np.std(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)])\n",
    "        skew = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].skew()\n",
    "        kurt = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].kurt()\n",
    "        median = globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)].median()\n",
    "        data[0], data[1] = np.percentile(globals()['df_'+str(i)+'_tmp']['TEMP'][120*j:120*(j+1)], q=[25,75])\n",
    "        data['Group'].append(i)\n",
    "        data['batch_num'].append(j+1)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(data[0],3))\n",
    "        data['75%'].append(np.round(data[1],3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(7876)})\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index',0,1], inplace = True)\n",
    "df = tmp\n",
    "\n",
    "for i in range(1,12):\n",
    "    globals()['df_temp_'+str(i)] = univariate_data(globals()['df_'+str(i)+'_tmp']['TEMP'], 0, len(df_1_tmp)+1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.iloc[:, :9].values\n",
    "X_mean = df['MEAN_TEMP'].values\n",
    "y = df['Group'].values - 1\n",
    "X_mean = X_mean.reshape(X_mean.shape[0], 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_mean_scale = scaler.fit_transform(X_mean)\n",
    "e = LabelEncoder()\n",
    "Y = e.fit_transform(y)\n",
    "Y = tf.keras.utils.to_categorical(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 96)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 6300, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.392197\n",
      "[LightGBM] [Info] Start training from score -2.388731\n",
      "[LightGBM] [Info] Start training from score -2.400916\n",
      "[LightGBM] [Info] Start training from score -2.395676\n",
      "[LightGBM] [Info] Start training from score -2.420368\n",
      "[LightGBM] [Info] Start training from score -2.406183\n",
      "[LightGBM] [Info] Start training from score -2.363111\n",
      "[LightGBM] [Info] Start training from score -2.423946\n",
      "[LightGBM] [Info] Start training from score -2.406183\n",
      "[LightGBM] [Info] Start training from score -2.381834\n",
      "[LightGBM] [Info] Start training from score -2.399166\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0.748730964467005\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(n_estimators=10)\n",
    "\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_metric= 'multi_logloss',\n",
    "         eval_set = [(X_test, y_test)])\n",
    "\n",
    "lgbm_predict = lgbm.predict(X_test)\n",
    "print(accuracy_score(y_test, lgbm_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6941624365482234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7138324873096447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 96)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "print(accuracy_score(y_test, dtc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626903553299492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 50, random_state = 96)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf_predict = clf.predict(X_test)\n",
    "print(accuracy_score(clf_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27411167512690354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=10, random_state = 96)\n",
    "ada.fit(X_train, y_train)\n",
    "ada_predict = ada.predict(X_test)\n",
    "print(accuracy_score(y_test, ada_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
