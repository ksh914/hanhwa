{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           TEMP    TIME\n",
       " 0       286.797       0\n",
       " 1       287.082       1\n",
       " 2       285.938       2\n",
       " 3       285.772       3\n",
       " 4       286.357       4\n",
       " ...         ...     ...\n",
       " 945115  933.812  945115\n",
       " 945116  934.304  945116\n",
       " 945117  934.530  945117\n",
       " 945118  934.443  945118\n",
       " 945119  934.625  945119\n",
       " \n",
       " [945120 rows x 2 columns],\n",
       "        MEAN_TEMP       STD      MIN      MAX      SKEW      KURT   MEDIAN  \\\n",
       " 0        284.174  1.466831  281.401  287.082  0.273302 -0.938145  283.754   \n",
       " 1        283.751  0.812237  282.306  286.186  0.917778  0.722954  283.646   \n",
       " 2        284.210  1.050080  282.354  286.597  0.380891 -0.499881  283.951   \n",
       " 3        284.221  1.073647  282.258  286.597  0.162330 -0.533757  284.141   \n",
       " 4        284.496  1.081369  282.258  286.949  0.196022 -0.205131  284.465   \n",
       " ...          ...       ...      ...      ...       ...       ...      ...   \n",
       " 31488    934.232  0.523646  932.681  935.319 -0.621865  0.769795  934.249   \n",
       " 31489    934.109  0.407589  933.475  935.378  0.824594  0.907333  934.049   \n",
       " 31490    933.815  0.503591  932.890  935.378  0.883268  1.217729  933.759   \n",
       " 31491    933.488  0.414537  932.523  934.455  0.134729 -0.596169  933.445   \n",
       " 31492    933.549  0.452777  932.523  934.625  0.360092 -0.168300  933.469   \n",
       " \n",
       "            25%      75%  Group   TIME  \n",
       " 0      283.220  285.415      1      0  \n",
       " 1      283.251  283.934      1      1  \n",
       " 2      283.455  284.948      1      2  \n",
       " 3      283.430  284.942      1      3  \n",
       " 4      283.802  285.137      1      4  \n",
       " ...        ...      ...    ...    ...  \n",
       " 31488  933.954  934.539     11  31488  \n",
       " 31489  933.812  934.398     11  31489  \n",
       " 31490  933.476  934.088     11  31490  \n",
       " 31491  933.174  933.778     11  31491  \n",
       " 31492  933.240  933.862     11  31492  \n",
       " \n",
       " [31493 rows x 11 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# 경향성이 있는 그래프의 선형적으로 증가할 수 있게 하는 함수 \n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "# x: 시간축인 함수 plot 함수\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
    "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14)\n",
    "    plt.grid(True)\n",
    "\n",
    "# 120개씩 자르는 함수 \n",
    "def univariate_data(dataset, start_index, end_index):\n",
    "    data = []\n",
    "    history_size = 120\n",
    "    start_index = start_index + history_size\n",
    "\n",
    "\n",
    "    for i in range(start_index, end_index, 120): # 0\n",
    "        indices = range(i - history_size, i) # [0 - 120] , [120 - 240] ...\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "    return np.array(data)\n",
    "\n",
    "for i in range(1,9):\n",
    "    globals()['df_'+str(i) ]= pd.read_csv('./temperature_csv_file/temp_df_{}.csv'.format(i), encoding = 'cp949')\n",
    "\n",
    "df_all = pd.concat([df_1, df_2], axis = 0)\n",
    "df_all = pd.concat([df_all, df_3], axis = 0)\n",
    "df_all = pd.concat([df_all, df_4], axis = 0)\n",
    "df_all = pd.concat([df_all, df_5], axis = 0)\n",
    "df_all = pd.concat([df_all, df_6], axis = 0)\n",
    "df_all = pd.concat([df_all, df_7], axis = 0)\n",
    "df_all = pd.concat([df_all, df_8], axis = 0)\n",
    "\n",
    "df_all = df_all[:601800].reset_index().drop(columns = ['index'], axis = 0)\n",
    "\n",
    "N = 6\n",
    "dx = (600 - df_1_tmp['TEMP'].mean()) / N # 전체 데이터에 대한 증가율 : 56.3785\n",
    "dx_minute = dx / (len(df_1_tmp)-1) # 분당 증가율\n",
    "\n",
    "time = np.arange(85920)\n",
    "slope = dx_minute * 2\n",
    "\n",
    "def trend(time, slope = 0):\n",
    "    return time * slope\n",
    "\n",
    "for i in range(1,8):\n",
    "    globals()['df_'+str(i)+'_tmp'] = df_all[85920*(i-1):85920*i].reset_index().drop(columns=['index'], axis=0)\n",
    "\n",
    "\n",
    "for i in range(1,8):\n",
    "    mean = globals()['df_'+str(i)+'_tmp']['TEMP'].mean()\n",
    "    diff  = 261.7292228119181 - mean\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] += diff\n",
    "\n",
    "for i in range(8,12):\n",
    "    globals()['df_'+str(i)+'_tmp'] = globals()['df_'+str(i-5)+'_tmp'].copy()\n",
    "\n",
    "for i in range(2,12):\n",
    "    series = np.round(trend(time, slope = slope) + globals()['df_'+str(i)+'_tmp']['TEMP'] + dx*(i-2), 3)\n",
    "    globals()['df_'+str(i)+'_tmp']['TEMP'] = series\n",
    "\n",
    "for i in range(1,12):\n",
    "    data = {'MEAN_TEMP' : [], 'STD' : [], 'MIN' : [], 'MAX' : [], 'SKEW' : [], 'KURT' : [], 'MEDIAN':[], '25%' : [], '75%' : [], 'Group' : []}\n",
    "\n",
    "    for j in range(0,85890,30):\n",
    "        temp = globals()['df_'+str(i)+'_tmp']['TEMP'][j:j+60]\n",
    "        MEAN = np.round(np.mean(temp), 3)\n",
    "        MIN = np.min(temp)\n",
    "        MAX = np.max(temp)\n",
    "        STD = np.std(temp)\n",
    "        median = temp.median()\n",
    "        skew = temp.skew()\n",
    "        kurt = temp.kurt()\n",
    "        a, b = np.percentile(temp, q = [25,75])\n",
    "\n",
    "        data['Group'].append(i)\n",
    "        data['MEAN_TEMP'].append(MEAN)\n",
    "        data['MIN'].append(MIN)\n",
    "        data['MAX'].append(MAX)\n",
    "        data['STD'].append(STD)\n",
    "        data['SKEW'].append(skew)\n",
    "        data['KURT'].append(kurt)\n",
    "        data['MEDIAN'].append(np.round(median,3))\n",
    "        data['25%'].append(np.round(a,3))\n",
    "        data['75%'].append(np.round(b,3))\n",
    "\n",
    "    globals()['group_'+str(i)] = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(len(group_1))\n",
    "TIME = pd.DataFrame({'TIME' : np.arange(31493)})\n",
    "tmp = pd.concat([group_1, group_2], axis = 0)\n",
    "tmp = pd.concat([tmp, group_3], axis = 0)\n",
    "tmp = pd.concat([tmp, group_4], axis = 0)\n",
    "tmp = pd.concat([tmp, group_5], axis = 0)\n",
    "tmp = pd.concat([tmp, group_6], axis = 0)\n",
    "tmp = pd.concat([tmp, group_7], axis = 0)\n",
    "tmp = pd.concat([tmp, group_8], axis = 0)\n",
    "tmp = pd.concat([tmp, group_9], axis = 0)\n",
    "tmp = pd.concat([tmp, group_10], axis = 0)\n",
    "tmp = pd.concat([tmp, group_11], axis = 0)\n",
    "tmp = tmp.reset_index()\n",
    "tmp = pd.concat([tmp, TIME], axis = 1)\n",
    "tmp.drop(columns = ['index'], inplace = True)\n",
    "df = tmp\n",
    "df\n",
    "\n",
    "tmp = np.arange(945120)\n",
    "TIME = pd.DataFrame({'TIME' : tmp})\n",
    "df_temp_all = pd.concat([df_1_tmp, df_2_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_3_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_4_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_5_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_6_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_7_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_8_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_9_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_10_tmp], axis = 0)\n",
    "df_temp_all = pd.concat([df_temp_all, df_11_tmp], axis = 0)\n",
    "df_temp_all = df_temp_all.reset_index().drop(columns = ['date', 'index','kst'])\n",
    "df_temp_all = pd.concat([df_temp_all,TIME], axis = 1)\n",
    "df_temp_all, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df_temp_all[['TEMP']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "\n",
    "timeseries = df_temp_all[['TEMP']].values.astype('float32')\n",
    " \n",
    "# train-test split for time series\n",
    "train_size = int(len(timeseries) * 0.8)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[:train_size], timeseries[train_size:]\n",
    " \n",
    "def create_dataset(dataset, lookback,stride = 30):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "        stride : how amny stride do you want to jump\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(0,len(dataset)-lookback, stride):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "def create_dataset2(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: A numpy array of time series, first dimension is the time steps\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback]\n",
    "        target = dataset[i+1:i+lookback+1]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "lookback = 60\n",
    "X_train, y_train = create_dataset2(train, lookback=lookback)\n",
    "X_test, y_test = create_dataset2(test, lookback=lookback)\n",
    "\n",
    "#y_train, y_test = y_train.unsqueeze(dim=1), y_test.unsqueeze(dim=1)\n",
    "# class DATA(data.Dataset):\n",
    "\n",
    "#     def __init__(self,lookback, stride):\n",
    "#         self.lookback = lookback\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "#         return \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([756036, 60, 1]), torch.Size([756036, 60, 1]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756036"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train RMSE 370.2845, test RMSE 655.5351\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\ddddd.ipynb 셀 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m X_batch, y_batch \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model(X_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\ddddd.ipynb 셀 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\hanhwa\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    876\u001b[0m         hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    880\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    881\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "class AirModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    " \n",
    "model = AirModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=256)\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    # Validation\n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        y_pred = model(X_test)\n",
    "        test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # shift train predictions for plotting\n",
    "    train_plot = np.ones_like(timeseries) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    y_pred = y_pred[:, -1, :]\n",
    "    train_plot[lookback:train_size] = model(X_train)[:, -1, :]\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(timeseries) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n",
    "# plot\n",
    "plt.plot(timeseries)\n",
    "plt.plot(train_plot, c='r')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (6299,1) into shape (0,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sejong\\Desktop\\hanhwa\\ddddd.ipynb 셀 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# shift test predictions for plotting\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     test_plot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones_like(np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(X_test))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     test_plot[train_size\u001b[39m+\u001b[39;49mlookback:\u001b[39mlen\u001b[39;49m(timeseries)] \u001b[39m=\u001b[39m model(X_test)[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# plot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sejong/Desktop/hanhwa/ddddd.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(timeseries)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (6299,1) into shape (0,1)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # shift train predictions for plotting\n",
    "    \n",
    "    train_plot = np.ones_like(np.arange(len(X_train)).reshape(-1,1)) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    y_pred = y_pred[:, -1, :]\n",
    "    train_plot[:len(X_train)] = model(X_train)[:, -1, :]\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(np.arange(len(X_test)).reshape(-1,1)) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, :]\n",
    "# plot\n",
    "plt.plot(timeseries)\n",
    "plt.plot(train_plot, c='r')\n",
    "plt.plot(test_plot, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25202, 60, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([25202, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_plot = np.ones_like(timeseries) * np.nan\n",
    "y_pred = model(X_train)\n",
    "print(y_pred.shape)\n",
    "y_pred = y_pred[:, -1, :]\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test(all_data, time_steps, for_periods): \n",
    "    \"\"\"\n",
    "    input:\n",
    "     data: dataframe with dates and price data\n",
    "    output:\n",
    "     X_train, y_train: data from 2013/1/1-2018-12/31 \n",
    "     X_test : data from 2019 - \n",
    "    time_steps: # of the input time steps \n",
    "    for_periods: # of the output time steps \n",
    "    \"\"\"\n",
    "    # create training and test set \n",
    "    train_len = int(len(all_data)*0.8)\n",
    "    ts_train = all_data[:train_len].values\n",
    "    ts_test = all_data[train_len:].values\n",
    "    ts_train_len = len(ts_train)\n",
    "    ts_test_len = len(ts_test)\n",
    "    \n",
    "    # create training data of s samples and t time steps \n",
    "    X_train = [] \n",
    "    y_train = [] \n",
    "    y_train_stacked = [] \n",
    "    for i in range(time_steps, ts_train_len - 1): \n",
    "        X_train.append(ts_train[i-time_steps:i,0])\n",
    "        y_train.append(ts_train[i:i+for_periods,0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    # Reshapng X_train for efficient modelling \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "    \n",
    "    # Preparing to creat X_test \n",
    "    inputs = pd.concat((all_data[\"Adj Close\"][:'2018'], all_data[\"Adj Close\"]['2019':]), axis=0).values\n",
    "    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    \n",
    "    X_test = []\n",
    "    for i in range(time_steps, ts_test_len+ time_steps- for_periods):\n",
    "        X_test.append(inputs[i-time_steps:i,0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test = ts_train_test(df_temp_all['TEMP'],60,1)\n",
    "X_train.shape[0], X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([286.797, 287.082, 285.938, ..., 934.53 , 934.443, 934.625])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_all['TEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanhwa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
